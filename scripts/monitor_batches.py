#!/usr/bin/env python3
"""
ë°°ì¹˜ ìƒíƒœ ëª¨ë‹ˆí„°ë§ ë° ìƒˆ ë°°ì¹˜ ì‹œì‘ ìŠ¤í¬ë¦½íŠ¸
ë§¤ì‹œê°„ ì‹¤í–‰ë˜ì–´ ì§„í–‰ ì¤‘ì¸ ë°°ì¹˜ë¥¼ í™•ì¸í•˜ê³  í•„ìš”ì‹œ ìƒˆ ë°°ì¹˜ë¥¼ ì‹œì‘
"""

import sys
import os
import json
import logging
from typing import List, Dict, Any

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from src.config.settings import Settings
from src.config.prompts import create_batch_request
from src.database.operations import NewsOperations, BatchOperations
from src.models.batch_status import BatchStatus
from src.utils.logging_utils import setup_logger, log_function_start, log_function_end, log_error, log_batch_status
from src.utils.file_utils import create_temp_file, write_jsonl_file, delete_file_safely
from src.utils.date_utils import get_kst_now, calculate_age_in_hours
import openai

logger = setup_logger(__name__)


class BatchMonitor:
    """ë°°ì¹˜ ëª¨ë‹ˆí„°ë§ ë° ê´€ë¦¬"""

    def __init__(self):
        openai.api_key = Settings.OPENAI_API_KEY
        self.client = openai.OpenAI()

    def check_active_batches(self) -> List[Dict[str, Any]]:
        """ì§„í–‰ ì¤‘ì¸ ë°°ì¹˜ í™•ì¸"""
        try:
            active_batches = BatchOperations.get_active_batches()

            for batch in active_batches:
                batch_id = batch["batch_id"]

                try:
                    # OpenAIì—ì„œ ë°°ì¹˜ ìƒíƒœ í™•ì¸
                    batch_obj = self.client.batches.retrieve(batch_id)
                    openai_status = batch_obj.status

                    log_batch_status(logger, batch_id, openai_status)

                    # ìƒíƒœ ì—…ë°ì´íŠ¸
                    if openai_status != batch["status"]:
                        update_data = {"status": openai_status}

                        if openai_status == "completed":
                            update_data["output_file_id"] = batch_obj.output_file_id
                        elif openai_status == "failed":
                            update_data["error_message"] = (
                                str(batch_obj.errors) if batch_obj.errors else "Unknown error"
                            )

                        BatchOperations.update_batch_status(batch_id, openai_status, **update_data)

                except Exception as e:
                    log_error(logger, e, f"checking batch status: {batch_id}")

                    # 24ì‹œê°„ ì´ìƒ ì‘ë‹µì´ ì—†ëŠ” ë°°ì¹˜ëŠ” ì‹¤íŒ¨ë¡œ ì²˜ë¦¬
                    age_hours = calculate_age_in_hours(batch["created_at"])
                    if age_hours > 25:  # 25ì‹œê°„ í›„ íƒ€ì„ì•„ì›ƒ
                        BatchOperations.update_batch_status(
                            batch_id, BatchStatus.FAILED.value, error_message=f"Timeout after {age_hours:.1f} hours"
                        )
                        logger.warning(f"â° Batch {batch_id} timed out after {age_hours:.1f} hours")

            return active_batches

        except Exception as e:
            log_error(logger, e, "checking active batches")
            return []

    def create_new_batch(self) -> bool:
        """ìƒˆ ë°°ì¹˜ ìƒì„±"""
        try:
            # ë¯¸ì²˜ë¦¬ ë‰´ìŠ¤ ì¡°íšŒ
            unprocessed_news = NewsOperations.get_unprocessed_news(Settings.BATCH_SIZE)

            if not unprocessed_news:
                logger.info("ğŸ“‹ No unprocessed news found")
                return False

            logger.info(f"ğŸ“‹ Found {len(unprocessed_news)} unprocessed news articles")

            # ë°°ì¹˜ ìš”ì²­ ë°ì´í„° ìƒì„±
            batch_requests = []
            for news in unprocessed_news:
                request = create_batch_request(news_id=str(news["id"]), title=news["title"], content=news["content"])
                batch_requests.append(request)

            # ì„ì‹œ JSONL íŒŒì¼ ìƒì„±
            temp_file = create_temp_file(suffix=".jsonl", prefix="batch_input_")

            try:
                # JSONL íŒŒì¼ ì‘ì„±
                written_count = write_jsonl_file(batch_requests, temp_file)
                logger.info(f"ğŸ“ Created batch input file with {written_count} requests")

                # OpenAIì— íŒŒì¼ ì—…ë¡œë“œ
                with open(temp_file, "rb") as file:
                    file_obj = self.client.files.create(file=file, purpose="batch")

                logger.info(f"ğŸ“¤ Uploaded input file: {file_obj.id}")

                # ë°°ì¹˜ ìƒì„±
                batch_obj = self.client.batches.create(
                    input_file_id=file_obj.id, endpoint="/v1/chat/completions", completion_window="24h"
                )

                logger.info(f"ğŸš€ Created batch: {batch_obj.id}")

                # Supabaseì— ë°°ì¹˜ ì •ë³´ ì €ì¥
                BatchOperations.create_batch_job(
                    batch_id=batch_obj.id, input_file_id=file_obj.id, total_count=len(batch_requests)
                )

                log_batch_status(logger, batch_obj.id, "created", f"{len(batch_requests)} requests")
                return True

            finally:
                # ì„ì‹œ íŒŒì¼ ì •ë¦¬
                delete_file_safely(temp_file)

        except Exception as e:
            log_error(logger, e, "creating new batch")
            return False

    def should_create_new_batch(self, active_batches: List[Dict[str, Any]]) -> bool:
        """ìƒˆ ë°°ì¹˜ ìƒì„± í•„ìš” ì—¬ë¶€ í™•ì¸"""
        try:
            # ì§„í–‰ ì¤‘ì¸ ë°°ì¹˜ê°€ ìˆìœ¼ë©´ ëŒ€ê¸°
            if active_batches:
                logger.info(f"â³ {len(active_batches)} active batches found, waiting...")
                return False

            # ë¯¸ì²˜ë¦¬ ë‰´ìŠ¤ê°€ ìˆëŠ”ì§€ í™•ì¸
            unprocessed_news = NewsOperations.get_unprocessed_news(1)  # 1ê°œë§Œ í™•ì¸
            if not unprocessed_news:
                logger.info("âœ… No unprocessed news found")
                return False

            # ë¯¸ì²˜ë¦¬ ë‰´ìŠ¤ í†µê³„
            stats = NewsOperations.get_news_stats()
            unprocessed_count = stats.get("unprocessed", 0)

            if unprocessed_count >= Settings.BATCH_SIZE:
                logger.info(f"ğŸ“Š {unprocessed_count} unprocessed articles found, creating batch...")
                return True
            elif unprocessed_count > 0:
                logger.info(f"ğŸ“Š Only {unprocessed_count} unprocessed articles (need {Settings.BATCH_SIZE})")
                return False

            return False

        except Exception as e:
            log_error(logger, e, "checking if new batch needed")
            return False

    def cleanup_old_data(self):
        """ì˜¤ë˜ëœ ë°ì´í„° ì •ë¦¬"""
        try:
            # ì˜¤ë˜ëœ ë°°ì¹˜ ì‘ì—… ì •ë¦¬ (7ì¼ ì´ìƒ)
            cleaned_count = BatchOperations.cleanup_old_batches(days_old=7)
            if cleaned_count > 0:
                logger.info(f"ğŸ§¹ Cleaned up {cleaned_count} old batch jobs")

        except Exception as e:
            log_error(logger, e, "cleaning up old data")


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    try:
        log_function_start(logger, "monitor_batches")

        # í™˜ê²½ë³€ìˆ˜ ê²€ì¦
        Settings.validate_required_env_vars()

        monitor = BatchMonitor()

        # 1. ì§„í–‰ ì¤‘ì¸ ë°°ì¹˜ ìƒíƒœ í™•ì¸
        logger.info("ğŸ” Checking active batches...")
        active_batches = monitor.check_active_batches()

        # 2. ìƒˆ ë°°ì¹˜ ìƒì„± í•„ìš” ì—¬ë¶€ í™•ì¸
        if monitor.should_create_new_batch(active_batches):
            logger.info("ğŸ†• Creating new batch...")
            success = monitor.create_new_batch()
            if success:
                logger.info("âœ… New batch created successfully")
            else:
                logger.warning("âš ï¸ Failed to create new batch")
        else:
            logger.info("â¸ï¸ No new batch needed at this time")

        # 3. ë°ì´í„° ì •ë¦¬
        monitor.cleanup_old_data()

        # 4. ìµœì¢… ìƒíƒœ ë¦¬í¬íŠ¸
        final_stats = NewsOperations.get_news_stats()
        final_active = BatchOperations.get_active_batches()

        logger.info(f"ğŸ“Š Final Report:")
        logger.info(f"   News: {final_stats}")
        logger.info(f"   Active batches: {len(final_active)}")

        log_function_end(logger, "monitor_batches")

    except Exception as e:
        log_error(logger, e, "main monitor_batches function")
        sys.exit(1)


if __name__ == "__main__":
    main()
