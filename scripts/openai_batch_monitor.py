#!/usr/bin/env python3
"""
OpenAI Batch API í´ë¦­ë² ì´íŠ¸ ì ìˆ˜ ì¸¡ì • - ë°°ì¹˜ ìƒì„± ë° ëª¨ë‹ˆí„°ë§

ì´ ëª¨ë“ˆì€ ë‹¤ìŒ ì‘ì—…ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤:
1. í™œì„± ë°°ì¹˜ í™•ì¸ ë° ì™„ë£Œëœ ë°°ì¹˜ í›„ì²˜ë¦¬
2. ë¯¸ì²˜ë¦¬ ë‰´ìŠ¤ì— ëŒ€í•œ ì‹ ê·œ ë°°ì¹˜ ìƒì„±
3. í´ë¦­ë² ì´íŠ¸ ì ìˆ˜ ì¸¡ì • ê²°ê³¼ë¥¼ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥

ì‹¤í–‰ ë°©ë²•:
    python -m scripts.openai_batch_monitor
    python scripts/openai_batch_monitor.py
"""

import os
import sys
import argparse
import logging

from src.config.settings import settings
from src.database.supabase_client import get_supabase_client
from src.core.openai_client import OpenAIClient
from src.core.prompt_generator import PromptGenerator
from src.core.bulk_updater import BulkUpdater
from src.core.batch_processor import BatchProcessor
from src.utils.logging_utils import setup_logging, get_logger

logger = get_logger(__name__)


def initialize_components():
    """ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™”"""
    logger.info("Initializing components")

    # Supabase í´ë¼ì´ì–¸íŠ¸
    supabase = get_supabase_client()

    # OpenAI í´ë¼ì´ì–¸íŠ¸
    openai_client = OpenAIClient(api_key=settings.OPENAI_API_KEY)

    # í”„ë¡¬í”„íŠ¸ ìƒì„±ê¸°
    prompt_generator = PromptGenerator()

    # ë²Œí¬ ì—…ë°ì´í„°
    bulk_updater = BulkUpdater(supabase=supabase)

    # ë°°ì¹˜ ì²˜ë¦¬ê¸°
    batch_processor = BatchProcessor(
        supabase=supabase, openai_client=openai_client, prompt_generator=prompt_generator, bulk_updater=bulk_updater
    )

    logger.info("Components initialized successfully")
    return batch_processor


def process_active_batch(batch_processor: BatchProcessor, active_batch: dict) -> str:
    """
    í™œì„± ë°°ì¹˜ í›„ì²˜ë¦¬

    Args:
        batch_processor: ë°°ì¹˜ ì²˜ë¦¬ê¸°
        active_batch: í™œì„± ë°°ì¹˜ ì •ë³´

    Returns:
        ë°°ì¹˜ ìƒíƒœ: "completed", "in_progress", "failed", "cancelled"
    """
    batch_id = active_batch["batch_id"]
    logger.info(f"Processing active batch: {batch_id}")

    try:
        # OpenAI ë°°ì¹˜ ìƒíƒœ í™•ì¸
        batch_status = batch_processor.check_batch_completion(batch_id)

        if not batch_status:
            logger.error("Failed to check batch status")
            return "failed"

        if batch_status == "completed":
            logger.info("Batch completed, processing results")

            # ë°°ì¹˜ ê²°ê³¼ ì²˜ë¦¬
            success = batch_processor.process_batch_results(batch_id)

            if success:
                # ë°°ì¹˜ ìƒíƒœë¥¼ ì™„ë£Œë¡œ ì—…ë°ì´íŠ¸
                batch_processor.update_batch_status(batch_id, "completed")
                logger.info("Batch processing completed successfully")
                return "completed"
            else:
                # ë°°ì¹˜ ìƒíƒœë¥¼ ì‹¤íŒ¨ë¡œ ì—…ë°ì´íŠ¸
                batch_processor.update_batch_status(batch_id, "failed", "Failed to process batch results")
                logger.error("Failed to process batch results")
                return "failed"

        elif batch_status == "failed":
            logger.warning("Batch failed on OpenAI side")
            batch_processor.update_batch_status(batch_id, "failed", "Batch failed on OpenAI platform")
            return "failed"

        elif batch_status == "cancelled":
            logger.warning("Batch was cancelled")
            batch_processor.update_batch_status(batch_id, "cancelled")
            return "cancelled"

        else:
            logger.info(f"Batch still in progress (status: {batch_status})")
            return "in_progress"

    except Exception as e:
        logger.error(f"Error processing active batch: {e}")
        batch_processor.update_batch_status(batch_id, "failed", f"Processing error: {str(e)}")
        return "failed"


def create_new_batch(batch_processor: BatchProcessor, batch_size: int = 100) -> bool:
    """
    ì‹ ê·œ ë°°ì¹˜ ìƒì„±

    Args:
        batch_processor: ë°°ì¹˜ ì²˜ë¦¬ê¸°
        batch_size: ë°°ì¹˜ í¬ê¸° (ê¸°ë³¸ê°’: 20)

    Returns:
        ìƒì„± ì„±ê³µ ì—¬ë¶€
    """
    logger.info(f"Creating new batch (size: {batch_size})")

    try:
        # ë¯¸ì²˜ë¦¬ Article ì¡°íšŒ
        pending_articles = batch_processor.get_pending_articles(limit=batch_size)

        if not pending_articles:
            logger.info("No pending articles found")
            return True  # ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ëŠ” ê²ƒì€ ì •ìƒ

        logger.info(f"Found {len(pending_articles)} pending articles")

        # ë°°ì¹˜ ìš”ì²­ ìƒì„±
        batch_info = batch_processor.create_batch_request(pending_articles)

        if not batch_info:
            logger.error("Failed to create batch request")
            return False

        # ë°°ì¹˜ ì •ë³´ë¥¼ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥
        saved_batch = batch_processor.save_batch_info_to_database(batch_info, len(pending_articles))

        if saved_batch:
            logger.info(f"New batch created successfully: {batch_info['id']}")
            return True
        else:
            logger.error("Failed to save batch info to database")
            return False

    except Exception as e:
        logger.error(f"Error creating new batch: {e}")
        return False


def run_batch_monitor(batch_size: int = 100) -> dict:
    """
    ë°°ì¹˜ ëª¨ë‹ˆí„°ë§ ì‹¤í–‰

    Args:
        batch_size: ë°°ì¹˜ í¬ê¸°

    Returns:
        ì‹¤í–‰ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
    """
    result = {"success": False, "active_batch_status": None, "new_batch_created": False, "errors": [], "message": ""}

    try:
        # ë¡œê¹… ì„¤ì •
        setup_logging("INFO")
        logger.info("Starting OpenAI Batch Monitor")

        # ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™”
        batch_processor = initialize_components()

        # 1. í™œì„± ë°°ì¹˜ í™•ì¸
        active_batch = batch_processor.check_active_batch()

        if active_batch:
            # 2. í™œì„± ë°°ì¹˜ í›„ì²˜ë¦¬
            logger.info("Found active batch, processing results")
            batch_status = process_active_batch(batch_processor, active_batch)
            result["active_batch_status"] = batch_status

            if batch_status == "completed":
                logger.info("Active batch completed, proceeding to create new batch")
                result["message"] = "Active batch completed successfully"
            elif batch_status == "in_progress":
                logger.info("Active batch still in progress, skipping new batch creation")
                result["message"] = "Active batch is still running - waiting for completion"
                result["success"] = True
                return result
            elif batch_status in ["failed", "cancelled"]:
                logger.warning(f"Active batch {batch_status}, proceeding to create new batch")
                result["message"] = f"Active batch {batch_status}, creating new batch"
            else:
                result["errors"].append(f"Unknown batch status: {batch_status}")
                return result
        else:
            logger.info("No active batch found")
            result["message"] = "No active batch found"

        # 3. ì‹ ê·œ ë°°ì¹˜ ìƒì„± (í™œì„± ë°°ì¹˜ê°€ ì™„ë£Œë˜ì—ˆê±°ë‚˜ ì—†ëŠ” ê²½ìš°ë§Œ)
        logger.info("Creating new batch")
        success = create_new_batch(batch_processor, batch_size)
        result["new_batch_created"] = success

        if success:
            logger.info("Batch monitoring completed successfully")
            result["success"] = True
            if result["message"]:
                result["message"] += " and new batch created"
            else:
                result["message"] = "New batch created successfully"
        else:
            result["errors"].append("Failed to create new batch")

        return result

    except Exception as e:
        error_msg = f"Unexpected error in batch monitor: {e}"
        logger.error(error_msg)
        result["errors"].append(error_msg)
        return result


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    parser = argparse.ArgumentParser(
        description="OpenAI Batch API í´ë¦­ë² ì´íŠ¸ ì ìˆ˜ ì¸¡ì • - ë°°ì¹˜ ìƒì„± ë° ëª¨ë‹ˆí„°ë§",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ì‹¤í–‰ ì˜ˆì‹œ:
  %(prog)s                          # ê¸°ë³¸ ì„¤ì •ìœ¼ë¡œ ì‹¤í–‰
  %(prog)s --batch-size 50          # ë°°ì¹˜ í¬ê¸° 50ìœ¼ë¡œ ì‹¤í–‰
        """,
    )

    parser.add_argument("--batch-size", type=int, default=100, help="ë°°ì¹˜ í¬ê¸° (ê¸°ë³¸ê°’: 100, ìµœëŒ€ 800)")

    args = parser.parse_args()

    # ë°°ì¹˜ í¬ê¸° ê²€ì¦
    if args.batch_size < 1 or args.batch_size > 800:
        print("ì˜¤ë¥˜: ë°°ì¹˜ í¬ê¸°ëŠ” 1~800 ì‚¬ì´ì—¬ì•¼ í•©ë‹ˆë‹¤.")
        sys.exit(1)

    # ë°°ì¹˜ ëª¨ë‹ˆí„°ë§ ì‹¤í–‰
    result = run_batch_monitor(batch_size=args.batch_size)

    # ê²°ê³¼ ì¶œë ¥
    if result["success"]:
        print("âœ… ë°°ì¹˜ ëª¨ë‹ˆí„°ë§ì´ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
        if result["message"]:
            print(f"ğŸ“‹ ìƒíƒœ: {result['message']}")

        # ìƒì„¸ ì •ë³´ ì¶œë ¥
        if result["active_batch_status"]:
            print(f"ğŸ“Š í™œì„± ë°°ì¹˜ ìƒíƒœ: {result['active_batch_status']}")
        if result["new_batch_created"]:
            print("ğŸ†• ìƒˆë¡œìš´ ë°°ì¹˜ê°€ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.")

        sys.exit(0)
    else:
        print("âŒ ë°°ì¹˜ ëª¨ë‹ˆí„°ë§ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤:")
        for error in result["errors"]:
            print(f"  - {error}")
        sys.exit(1)


if __name__ == "__main__":
    main()
