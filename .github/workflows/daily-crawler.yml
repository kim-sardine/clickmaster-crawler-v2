name: Daily News Crawler

on:
  schedule:
    # ë§¤ì¼ ì˜¤ì „ 6ì‹œ (KST 15ì‹œ = UTC 06ì‹œ)ì— ì‹¤í–‰
    - cron: '0 21 * * *'  # UTC 21ì‹œ = KST 06ì‹œ
  workflow_dispatch:  # ìˆ˜ë™ ì‹¤í–‰ ê°€ëŠ¥

jobs:
  crawl-news:
    runs-on: ubuntu-latest
    timeout-minutes: 60  # 1ì‹œê°„ íƒ€ì„ì•„ì›ƒ
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
        
    - name: Cache dependencies
      uses: actions/cache@v3
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements.txt') }}
        restore-keys: |
          ${{ runner.os }}-pip-
          
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        
    - name: Run news crawler
      env:
        NAVER_CLIENT_ID: ${{ secrets.NAVER_CLIENT_ID }}
        NAVER_CLIENT_SECRET: ${{ secrets.NAVER_CLIENT_SECRET }}
        OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
        SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
        SUPABASE_KEY: ${{ secrets.SUPABASE_KEY }}
      run: |
        echo "ğŸš€ Starting daily news crawling..."
        python scripts/crawl_news.py
        
    - name: Upload logs on failure
      if: failure()
      uses: actions/upload-artifact@v3
      with:
        name: crawler-logs-${{ github.run_number }}
        path: |
          *.log
          logs/
        retention-days: 7 