---
description: Supabase Operations
alwaysApply: false
---

# Supabase ë°ì´í„°ë² ì´ìŠ¤ ì—°ì‚°

## ğŸ—„ï¸ ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° âœ… êµ¬í˜„ì™„ë£Œ

### í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” (`src/database/supabase_client.py`)
```python
from src.database.supabase_client import get_supabase_client

# ì‹±ê¸€í†¤ íŒ¨í„´ìœ¼ë¡œ êµ¬í˜„ë¨
client = get_supabase_client()
supabase = client.client  # Supabase Client ì¸ìŠ¤í„´ìŠ¤
```

### í™˜ê²½ ë³€ìˆ˜ ê´€ë¦¬ âœ… êµ¬í˜„ì™„ë£Œ
- `SUPABASE_URL`: Supabase í”„ë¡œì íŠ¸ URL
- `SUPABASE_SERVICE_ROLE_KEY`: ì„œë¹„ìŠ¤ ë¡¤ í‚¤ (ì½ê¸°/ì“°ê¸° ê¶Œí•œ)
- í™˜ê²½ë³€ìˆ˜ ê²€ì¦ ë¡œì§ í¬í•¨ (`src/config/settings.py`)

## ğŸ“ ê¸°ë³¸ CRUD ì—°ì‚° âœ… êµ¬í˜„ì™„ë£Œ

### ê¸°ì‚¬ ë°ì´í„° ì‚½ì… (`src/database/operations.py`)
```python
class DatabaseOperations:
    def insert_article(self, article: Article) -> Dict[str, Any]:
        """ê¸°ì‚¬ ë°ì´í„° ì‚½ì…"""
        # ê¸°ì ì •ë³´ ìë™ ì¡°íšŒ/ìƒì„±
        journalist = self.get_or_create_journalist(article.journalist_name, article.publisher)
        article.journalist_id = journalist["id"]
        
        # ê¸°ì‚¬ ì‚½ì…
        result = self.client.client.table('articles').insert(article.to_dict()).execute()
        return result.data[0]
```

### ê¸°ì ì •ë³´ ì¡°íšŒ/ì‚½ì… âœ… êµ¬í˜„ì™„ë£Œ
```python
def get_or_create_journalist(self, name: str, publisher: str, naver_uuid: Optional[str] = None):
    """ê¸°ì ì •ë³´ ì¡°íšŒ ë˜ëŠ” ìƒì„±"""
    # ìµëª… ê¸°ì ì²˜ë¦¬ ë¡œì§ í¬í•¨
    if name in ["ìµëª…", "ê¸°ì", "", " "]:
        name = f"ìµëª…ê¸°ì_{publisher}"
    
    # ê¸°ì¡´ ê¸°ì ì¡°íšŒ
    existing = self.client.client.table('journalists').select('*').eq('name', name).eq('publisher', publisher).execute()
    
    if existing.data:
        return existing.data[0]
    
    # ìƒˆ ê¸°ì ìƒì„±
    journalist = Journalist(name=name, publisher=publisher, naver_uuid=naver_uuid)
    return self.client.client.table('journalists').insert(journalist.to_dict()).execute().data[0]
```

## ğŸ” ì¿¼ë¦¬ íŒ¨í„´ âœ… êµ¬í˜„ì™„ë£Œ

### ë°°ì¹˜ ì‚½ì… (ì„±ëŠ¥ ìµœì í™”)
```python
def bulk_insert_articles(self, articles: List[Article]) -> List[Dict[str, Any]]:
    """ê¸°ì‚¬ ë°°ì¹˜ ì‚½ì… (ê¸°ì ì •ë³´ ìºì‹±ìœ¼ë¡œ ì„±ëŠ¥ ìµœì í™”)"""
    journalist_cache = {}  # ê¸°ì ì •ë³´ ìºì‹±
    inserted_articles = []
    
    for article in articles:
        # ìºì‹œì—ì„œ ê¸°ì ì •ë³´ ì¡°íšŒ
        journalist_key = f"{article.journalist_name}_{article.publisher}"
        if journalist_key not in journalist_cache:
            journalist = self.get_or_create_journalist(article.journalist_name, article.publisher)
            journalist_cache[journalist_key] = journalist
        
        # ê¸°ì‚¬ ì‚½ì…
        article.journalist_id = journalist_cache[journalist_key]["id"]
        result = self.client.client.table('articles').insert(article.to_dict()).execute()
        if result.data:
            inserted_articles.append(result.data[0])
    
    return inserted_articles
```

### ì¤‘ë³µ ì²´í¬ âœ… êµ¬í˜„ì™„ë£Œ
```python
def check_duplicate_article(self, naver_url: str) -> bool:
    """ì¤‘ë³µ ê¸°ì‚¬ ì²´í¬"""
    result = self.client.client.table('articles').select('id').eq('naver_url', naver_url).execute()
    return len(result.data) > 0
```

### ë¯¸ì²˜ë¦¬ ê¸°ì‚¬ ì¡°íšŒ âœ… êµ¬í˜„ì™„ë£Œ
```python
def get_unprocessed_articles(self, limit: int = 1000) -> List[Dict[str, Any]]:
    """OpenAI ì²˜ë¦¬ë˜ì§€ ì•Šì€ ê¸°ì‚¬ ì¡°íšŒ"""
    return self.client.client.table('articles').select('*').is_('clickbait_score', 'null').limit(limit).execute().data
```

## ğŸ“Š í†µê³„ ë° ì§‘ê³„ âœ… êµ¬í˜„ì™„ë£Œ

### ê¸°ì í†µê³„ ê´€ë¦¬ (`scripts/sync_journalist_stats.py`)
```python
def update_journalist_stats_manual(self, journalist_id: str) -> bool:
    """íŠ¹ì • ê¸°ìì˜ í†µê³„ ìˆ˜ë™ ì—…ë°ì´íŠ¸"""
    # í•´ë‹¹ ê¸°ìì˜ ëª¨ë“  ê¸°ì‚¬ í†µê³„ ê³„ì‚°
    # article_count, avg_clickbait_score, max_score ì—…ë°ì´íŠ¸

def update_all_journalist_stats(self) -> Dict[str, Any]:
    """ëª¨ë“  ê¸°ì í†µê³„ ì—…ë°ì´íŠ¸"""
    # ëª¨ë“  ê¸°ìì— ëŒ€í•´ í†µê³„ ì¬ê³„ì‚° ë° ì—…ë°ì´íŠ¸

def get_journalist_stats_summary(self) -> Dict[str, Any]:
    """ê¸°ì í†µê³„ ìš”ì•½ ì¡°íšŒ"""
    # ì „ì²´ ê¸°ì ìˆ˜, í™œì„± ê¸°ì ìˆ˜, ì ìˆ˜ ìˆëŠ” ê¸°ì ìˆ˜ ë“± ë°˜í™˜

def fix_inconsistent_stats(self) -> Dict[str, Any]:
    """í†µê³„ ë¶ˆì¼ì¹˜ ê°ì§€ ë° ìˆ˜ì •"""
    # ê¸°ì‚¬ ìˆ˜ì™€ ì‹¤ì œ í†µê³„ ê°„ ë¶ˆì¼ì¹˜ ê°ì§€ ë° ìˆ˜ì •
```

## ğŸ”„ ë°°ì¹˜ ìƒíƒœ ê´€ë¦¬ âŒ ë¯¸êµ¬í˜„

### ë°°ì¹˜ ìƒíƒœ í…Œì´ë¸” (í–¥í›„ êµ¬í˜„ ì˜ˆì •)
```sql
CREATE TABLE batch_status (
  id UUID PRIMARY KEY,
  batch_id TEXT UNIQUE NOT NULL,
  status TEXT NOT NULL,
  created_at TIMESTAMP DEFAULT NOW(),
  updated_at TIMESTAMP DEFAULT NOW(),
  input_file_id TEXT,
  output_file_id TEXT,
  error_file_id TEXT,
  request_count INTEGER DEFAULT 0,
  completed_count INTEGER DEFAULT 0,
  failed_count INTEGER DEFAULT 0
);
```

## ğŸ› ï¸ ì—ëŸ¬ í•¸ë“¤ë§ âœ… ë¶€ë¶„ êµ¬í˜„

### ì—°ê²° í…ŒìŠ¤íŠ¸ âœ… êµ¬í˜„ì™„ë£Œ
```python
# src/database/supabase_client.py
def test_connection(self) -> bool:
    """ì—°ê²° í…ŒìŠ¤íŠ¸"""
    try:
        result = self.client.table("articles").select("id").limit(1).execute()
        return True
    except Exception:
        return False
```

### ì¬ì‹œë„ ë©”ì»¤ë‹ˆì¦˜ âŒ ë¯¸êµ¬í˜„ (í–¥í›„ ì¶”ê°€ ì˜ˆì •)
```python
# í–¥í›„ êµ¬í˜„ ì˜ˆì •
import time
from functools import wraps

def retry_db_operation(max_retries=3, delay=1):
    def decorator(func):
        @wraps(func)
        def wrapper(*args, **kwargs):
            for attempt in range(max_retries):
                try:
                    return func(*args, **kwargs)
                except Exception as e:
                    if attempt == max_retries - 1:
                        raise
                    time.sleep(delay * (2 ** attempt))
        return wrapper
    return decorator
```

## ğŸ“ˆ ì„±ëŠ¥ ìµœì í™” âœ… êµ¬í˜„ì™„ë£Œ

### ìºì‹± ì „ëµ
- ê¸°ì ì •ë³´ ë©”ëª¨ë¦¬ ìºì‹± (`journalist_cache`)
- ë°°ì¹˜ ì‚½ì…ìœ¼ë¡œ DB í˜¸ì¶œ ìµœì†Œí™”
- ì‹±ê¸€í†¤ íŒ¨í„´ìœ¼ë¡œ í´ë¼ì´ì–¸íŠ¸ ì¬ì‚¬ìš©

### ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±
- ë°°ì¹˜ ì²˜ë¦¬ ì‹œ ìŠ¤íŠ¸ë¦¬ë° ë°©ì‹
- ì²˜ë¦¬ ì™„ë£Œ í›„ ì¦‰ì‹œ ë©”ëª¨ë¦¬ í•´ì œ
- ìƒì„¸í•œ ë¡œê¹…ìœ¼ë¡œ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§

## ğŸ”’ ë³´ì•ˆ ë° ê¶Œí•œ âœ… êµ¬í˜„ì™„ë£Œ

### í™˜ê²½ë³€ìˆ˜ ê´€ë¦¬
- `.env` íŒŒì¼ì„ í†µí•œ ì•ˆì „í•œ í‚¤ ê´€ë¦¬
- í™˜ê²½ë³€ìˆ˜ ê²€ì¦ ë¡œì§ (`settings.validate()`)
- ì„œë¹„ìŠ¤ ë¡¤ í‚¤ ì‚¬ìš©ìœ¼ë¡œ ëª¨ë“  ê¶Œí•œ ë³´ì¥

### ë°ì´í„° ê²€ì¦
- Article ëª¨ë¸ì—ì„œ ìë™ ë°ì´í„° ê²€ì¦
- URL í˜•ì‹ ê²€ì¦
- ì ìˆ˜ ë²”ìœ„ ê²€ì¦ (0-100)

## ğŸš€ ì‹¤í–‰ ì˜ˆì‹œ

### ê¸°ë³¸ ì‚¬ìš©ë²•
```python
from src.database.operations import DatabaseOperations

db_ops = DatabaseOperations()

# ê¸°ì‚¬ ì‚½ì…
article = Article(title="ì œëª©", content="ë‚´ìš©", ...)
result = db_ops.insert_article(article)

# ë°°ì¹˜ ì‚½ì…
articles = [article1, article2, ...]
results = db_ops.bulk_insert_articles(articles)

# ì¤‘ë³µ ì²´í¬
is_duplicate = db_ops.check_duplicate_article("https://n.news.naver.com/...")
```

### í†µê³„ ë™ê¸°í™”
```bash
# ê¸°ì í†µê³„ ë™ê¸°í™” ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰
python scripts/sync_journalist_stats.py

# í†µê³„ ë¶ˆì¼ì¹˜ ìˆ˜ì •
python scripts/sync_journalist_stats.py --fix-inconsistencies

# ì „ì²´ í†µê³„ ê°•ì œ ì—…ë°ì´íŠ¸
python scripts/sync_journalist_stats.py --full-update
```

## ğŸ“Š í˜„ì¬ ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤í‚¤ë§ˆ

### articles í…Œì´ë¸” (êµ¬í˜„ì™„ë£Œ)
- id: UUID (Primary Key)
- title: TEXT
- content: TEXT
- journalist_id: UUID (Foreign Key)
- journalist_name: TEXT
- publisher: TEXT
- published_at: TIMESTAMP
- naver_url: TEXT
- clickbait_score: INTEGER (0-100)
- clickbait_explanation: TEXT
- created_at: TIMESTAMP
- updated_at: TIMESTAMP

### journalists í…Œì´ë¸” (êµ¬í˜„ì™„ë£Œ)
- id: UUID (Primary Key)
- name: TEXT
- naver_uuid: TEXT
- publisher: TEXT
- article_count: INTEGER
- avg_clickbait_score: DECIMAL
- max_score: INTEGER
- created_at: TIMESTAMP
- updated_at: TIMESTAMP

## ğŸ”® í–¥í›„ ê°œì„  ê³„íš

### ê³ ê¸‰ ì¿¼ë¦¬ ê¸°ëŠ¥
- ì „ë¬¸ê²€ìƒ‰ ì¸ë±ìŠ¤ í™œìš©
- ë³µí•© ì¡°ê±´ ê²€ìƒ‰ ìµœì í™”
- ì‹¤ì‹œê°„ í†µê³„ ë·° êµ¬í˜„

### ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§
- ì¿¼ë¦¬ ì‹¤í–‰ ì‹œê°„ ì¶”ì 
- ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ëª¨ë‹ˆí„°ë§
- DB ì—°ê²° í’€ë§ êµ¬í˜„

- ëŒ€ëŸ‰ ë°ì´í„° ìŠ¤íŠ¸ë¦¬ë° ì²˜ë¦¬
- ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ëª¨ë‹ˆí„°ë§
- ê°€ë¹„ì§€ ì»¬ë ‰ì…˜ ìµœì í™”
