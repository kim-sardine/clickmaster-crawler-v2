---
alwaysApply: true
description: "프로젝트 전반적인 개요와 구조"
---

# 클릭마스터 크롤러 - 프로젝트 개요

## 🎯 프로젝트 목표
네이버 뉴스를 크롤링하여 각 뉴스의 **Clickbait 정도를 0~100 정수 값으로 측정**하고, 판단 근거와 함께 Supabase 데이터베이스에 저장하는 시스템

## 🏗️ 시스템 아키텍처

### 3단계 파이프라인
1. **뉴스 크롤링 단계** → 네이버 뉴스 데이터 수집 및 Supabase 저장
2. **AI 분석 단계** → OpenAI Batch API를 통한 Clickbait 점수 측정
3. **결과 처리 단계** → 배치 결과 파싱 및 뉴스 데이터 업데이트

### 디렉토리 구조
```
clickmaster-crawler/
├── src/
│   ├── crawlers/          # 크롤링 로직
│   ├── database/          # Supabase 클라이언트 및 DB 연산
│   ├── core/              # OpenAI Batch API 핵심 로직
│   ├── models/            # 데이터 모델
│   ├── config/            # 설정 파일 (키워드, 프롬프트 등)
│   └── utils/             # 공통 유틸리티
├── scripts/               # 독립 실행 스크립트
├── .github/workflows/     # GitHub Actions 워크플로우
└── requirements.txt       # 의존성 목록
```

## 🔧 핵심 기술 스택
- **Python 3.12+** - 메인 개발 언어
- **Supabase** - 메인 데이터베이스 (PostgreSQL)
- **OpenAI API** - Batch API를 통한 Clickbait 점수 측정
- **Naver Open API** - 뉴스 검색 API
- **Requests/BeautifulSoup** - 웹 크롤링
- **GitHub Actions** - 자동화 워크플로우

## 📊 데이터 플로우
```
네이버 뉴스 → 크롤링 → Supabase 저장 → OpenAI Batch API → 결과 파싱 → 최종 업데이트
```

## 🎨 개발 원칙
- **모듈화**: 각 단계별로 독립적인 스크립트 작성
- **재사용성**: 공통 로직은 utils 모듈로 분리
- **에러 핸들링**: 각 단계별 실패 시 복구 가능한 구조
- **로깅**: 모든 중요 작업에 대한 상세 로그 기록
- **설정 외부화**: 환경변수 및 설정 파일을 통한 구성 관리
