---
description: OpenAI Batch API Logic
---

# OpenAI Batch API를 통한 Clickbait 점수 측정 시스템

## 🎯 개요
네이버 뉴스 Article 데이터에 대해 OpenAI Batch API를 활용하여 clickbait 점수(0-100)와 판단 근거를 측정하는 시스템

## 📋 스크립트 실행 순서

### 1. 배치 상태 확인 단계 ✅ 구현완료
- **목적**: 현재 실행중인 OpenAI batch 작업 존재 여부 확인
- **구현**: 
  - Supabase `batch_status` 테이블 조회
  - `status IN ('pending', 'in_progress', 'validating', 'finalizing')` 조건으로 모든 활성 배치 검색
  - 모든 활성 배치를 순차적으로 처리 (동시 실행 방지)

### 2. 배치 후처리 로직 (실행중인 배치가 존재하는 경우) ✅ 구현완료

#### 2-1. 배치 결과 파일 다운로드
```python
# OpenAI Python API 활용
client = OpenAI(api_key=openai_api_key)
batch = client.batches.retrieve(batch_id)
if batch.status == 'completed':
    result_file = client.files.content(batch.output_file_id)
```
- **멱등성 최적화**: 이미 완료된 배치는 재처리하지 않음
- **캐싱**: 다운로드한 결과를 임시 저장하여 재시도 시 활용

#### 2-2. 결과 파싱 및 데이터 추출 ✅ 구현완료
- **입력**: OpenAI Batch API 결과 JSONL 파일
- **출력**: Article별 `clickbait_score`, `clickbait_explanation` 매핑
- **구현 특징**:
  - JSONL 파일 라인별 파싱
  - custom_id를 통한 Article ID 매핑 (`article_{uuid}` 형식)
  - JSON Schema 응답 형식으로 안정적인 파싱
  - 상세한 파싱 에러 메시지 및 로깅
  - score 값 검증 (reason → clickbait_explanation 매핑)

#### 2-3. Supabase Article 테이블 Bulk 업데이트 ✅ 구현완료
```python
# Bulk upsert를 위한 데이터 준비
bulk_updates = []
for article_id, result in parsed_results.items():
    bulk_updates.append({
        'id': article_id,
        'clickbait_score': result['clickbait_score'],
        'clickbait_explanation': result['clickbait_explanation'],
        'updated_at': datetime.now().isoformat()
    })

# 한번에 모든 데이터 업데이트 (성능상 훨씬 효율적)
if bulk_updates:
    response = supabase.table('articles').upsert(bulk_updates).execute()
    logger.info(f"Bulk updated {len(bulk_updates)} articles")
```
- **멱등성 보장**: 이미 점수가 있는 기사도 안전하게 업데이트
- **실패 시 개별 처리**: Bulk 실패 시 개별 업데이트로 fallback

#### 2-4. 배치 상태 업데이트 및 신규 배치 생성으로 이동 ✅ 구현완료
- `batch_status` 테이블의 해당 배치 상태를 `completed`로 업데이트
- 처리된 Article 수 기록
- 에러 발생 시 `failed` 상태로 업데이트 및 상세 에러 메시지 저장
- 모든 활성 배치 처리 완료 후 신규 배치 생성 단계로 이동

### 3. 신규 배치 생성 로직 (실행중인 배치가 없는 경우) ✅ 구현완료

#### 3-1. 대상 Article 데이터 조회
```python
# clickbait_score가 null인 데이터 조회 (오래된 순)
articles = supabase.table('articles').select('*')\
    .is_('clickbait_score', 'null')\
    .order('created_at', desc=False)\
    .limit(batch_size)\
    .execute()
```
- **배치 크기**: 기본 100개, 최대 800개 (파라미터로 조정 가능)
- **동시성 제어**: 이중/삼중 체크로 동시 배치 생성 방지

#### 3-2. 프롬프트 생성 및 Batch API 입력 포맷 변환 ✅ 구현완료
```python
# 각 Article별 프롬프트 생성
batch_requests = []
for article in articles:
    prompt = generate_clickbait_prompt(article['title'], article['content'])
    batch_request = {
        "custom_id": f"article_{article['id']}",
        "method": "POST",
        "url": "/v1/chat/completions",
        "body": {
            "model": "gpt-4o-mini",
            "messages": [
                {
                    "role": "system",
                    "content": "당신은 뉴스의 제목과 내용을 분석하여 클릭베이트 여부를 판단하는 전문가입니다..."
                },
                {"role": "user", "content": prompt}
            ],
            "response_format": {
                "type": "json_schema",
                "json_schema": {
                    "name": "clickbait_evaluation",
                    "strict": True,
                    "schema": CLICKBAIT_EVALUATION_SCHEMA
                }
            }
        }
    }
    batch_requests.append(batch_request)
```

#### 3-3. OpenAI Batch API 생성 호출 ✅ 구현완료
```python
# JSONL 파일 생성 및 업로드
jsonl_content = "\n".join(json.dumps(req) for req in batch_requests)
with tempfile.NamedTemporaryFile(mode="w", suffix=".jsonl", delete=False) as f:
    f.write(jsonl_content)
    temp_file_path = f.name

# 파일 업로드
with open(temp_file_path, "rb") as file:
    uploaded_file = client.files.create(file=file, purpose="batch")

# 배치 생성
batch = client.batches.create(
    input_file_id=uploaded_file.id,
    endpoint="/v1/chat/completions",
    completion_window="24h"
)

# Supabase batch_status 테이블에 배치 정보 저장
supabase.table('batch_status').insert({
    'batch_id': batch.id,
    'status': 'in_progress',
    'request_count': len(articles),
    'input_file_id': uploaded_file.id,
    'created_at': datetime.now().isoformat()
}).execute()
```

## 🔧 구현 파일 구조 ✅ 구현완료

### 스크립트 파일
- `scripts/openai_batch_monitor.py`: 메인 실행 스크립트 (배치 모니터링 및 생성)

### 핵심 모듈
- `src/core/batch_processor.py`: 배치 처리 핵심 로직 (멱등성, 동시성 제어 포함)
- `src/core/openai_client.py`: OpenAI API 클라이언트 래퍼
- `src/core/prompt_generator.py`: Clickbait 판단 프롬프트 생성 및 JSON Schema 정의
- `src/core/bulk_updater.py`: Bulk upsert 최적화 및 에러 핸들링

### 설정 파일
- `src/config/settings.py`: 환경변수 및 기본 설정 관리

### 유틸리티 모듈
- `src/utils/batch_utils.py`: 배치 분할, 재시도 로직
- `src/utils/performance_monitor.py`: 성능 모니터링 및 메트릭

## 📊 데이터베이스 스키마 참고

### batch_status 테이블 ✅ 구현완료
```sql
CREATE TABLE batch_status (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    batch_id TEXT UNIQUE NOT NULL,
    status TEXT NOT NULL, -- 'pending', 'in_progress', 'validating', 'finalizing', 'completed', 'failed', 'cancelled'
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    updated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    input_file_id TEXT,
    output_file_id TEXT,
    error_file_id TEXT,
    request_count INTEGER DEFAULT 0,
    completed_count INTEGER DEFAULT 0,
    failed_count INTEGER DEFAULT 0,
    metadata JSONB,
    error_message TEXT
);
```

## ⚙️ 환경 설정

### 환경 변수
- `OPENAI_API_KEY`: OpenAI API 키
- `SUPABASE_URL`: Supabase 프로젝트 URL  
- `SUPABASE_SERVICE_ROLE_KEY`: Supabase 서비스 키

### GitHub Actions 스케줄링 ✅ 구현완료
- **실행 주기**: 매시간 27분 (부하 분산을 위해 정각 피함)
- **Cron 표현식**: `27 * * * *`
- **타임아웃**: 45분
- **워크플로우 파일**: `.github/workflows/hourly-batch-monitor.yml`

## ⚡ 성능 최적화

### Bulk Upsert 장점
- **성능 향상**: 개별 업데이트 대신 한번의 요청으로 처리 (최대 800개까지)
- **네트워크 효율성**: API 요청 횟수 대폭 감소 (800회 → 1회)
- **트랜잭션 보장**: 모든 업데이트가 하나의 트랜잭션으로 처리

### Bulk Upsert 사용법
```python
# upsert는 id를 기준으로 존재하면 UPDATE, 없으면 INSERT
bulk_updates = [
    {'id': 1, 'clickbait_score': 85, 'clickbait_explanation': '...'},
    {'id': 2, 'clickbait_score': 42, 'clickbait_explanation': '...'}
]
response = supabase.table('Article').upsert(bulk_updates).execute()
```

### 배치 크기 고려사항 ✅ 구현완료
- **기본 배치 크기**: 100개 (안정성 우선)
- **최대 배치 크기**: 800개 (파라미터로 조정 가능)
- **메모리 사용량**: 배치 처리 후 즉시 메모리 해제
- **실패 시 재시도**: 다음 배치 실행 시 자동 재처리 (clickbait_score가 null인 기사 재조회)

## 🛡️ 에러 핸들링

### 배치 처리 실패 시
- `batch` 테이블 상태를 `failed`로 업데이트
- 에러 메시지 기록
- 슬랙/이메일 알림 발송

### 개별 Article 파싱 실패 시  
- 파싱 실패한 Article은 bulk_updates에서 제외
- 실패한 Article ID와 에러 내용 로그 기록
- 다음 배치에서 재시도 (clickbait_score가 여전히 null이므로)

### Bulk Upsert 실패 시
- 네트워크 오류나 DB 제약 조건 위반 시 전체 배치 실패
- 실패 시 개별 upsert로 fallback 처리 옵션
- 배치를 더 작은 단위로 분할하여 재시도

### OpenAI API 한도 초과 시
- 배치 생성 실패 시 다음 시간에 재시도
- Rate limit 에러 처리

## 📝 로깅 전략

### 로그 레벨별 기록 사항
- **INFO**: 배치 생성/완료, 처리된 Article 수
- **WARNING**: 개별 파싱 실패, API 응답 이상
- **ERROR**: 배치 처리 실패, DB 연결 실패
- **DEBUG**: 상세 처리 과정, API 요청/응답

### 로그 파일 구조
```
logs/
├── batch_processing.log      # 메인 로그
├── openai_api.log           # OpenAI API 관련 로그  
└── error.log                # 에러만 별도 기록
```

## 🧪 테스트 전략

### 단위 테스트
- 프롬프트 생성 로직 테스트
- 배치 결과 파싱 로직 테스트
- Database 연산 테스트

### 통합 테스트  
- 전체 배치 처리 플로우 테스트
- OpenAI API Mock을 활용한 End-to-End 테스트

### 성능 테스트
- 800개 Article 배치 처리 시간 측정
- 메모리 사용량 모니터링
