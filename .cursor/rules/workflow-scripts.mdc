
# ì›Œí¬í”Œë¡œìš° ìŠ¤í¬ë¦½íŠ¸ ê°€ì´ë“œ

## ğŸ“‹ ìŠ¤í¬ë¦½íŠ¸ êµ¬ì¡° âœ… êµ¬í˜„ì™„ë£Œ

### ë…ë¦½ ì‹¤í–‰ ì›ì¹™ (ëª¨ë“  ìŠ¤í¬ë¦½íŠ¸ì— ì ìš©ë¨)
ê° ìŠ¤í¬ë¦½íŠ¸ëŠ” ë‹¤ìŒ ì¡°ê±´ì„ ë§Œì¡±í•©ë‹ˆë‹¤:
- **ë…ë¦½ì„±**: ë‹¤ë¥¸ ìŠ¤í¬ë¦½íŠ¸ì— ì˜ì¡´í•˜ì§€ ì•Šê³  ì‹¤í–‰ ê°€ëŠ¥
- **ë©±ë“±ì„±**: ì—¬ëŸ¬ ë²ˆ ì‹¤í–‰í•´ë„ ì•ˆì „í•œ ê²°ê³¼
- **ë¡œê¹…**: ì‹¤í–‰ ê³¼ì •ê³¼ ê²°ê³¼ë¥¼ ìƒì„¸íˆ ê¸°ë¡
- **ì—ëŸ¬ í•¸ë“¤ë§**: ì‹¤íŒ¨ ì‹œ ì ì ˆí•œ ë³µêµ¬ ë©”ì»¤ë‹ˆì¦˜

### ê³µí†µ êµ¬ì¡° í…œí”Œë¦¿ âœ… êµ¬í˜„ì™„ë£Œ
```python
#!/usr/bin/env python3
"""
ìŠ¤í¬ë¦½íŠ¸ ì„¤ëª…
"""

import sys
import logging
import argparse
from datetime import datetime
from pathlib import Path

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from src.config.settings import settings

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=getattr(logging, settings.LOG_LEVEL),
    format=settings.LOG_FORMAT,
    handlers=[
        logging.FileHandler(f"logs/{ìŠ¤í¬ë¦½íŠ¸ëª…}_{datetime.now().strftime('%Y%m%d')}.log"),
        logging.StreamHandler(sys.stdout),
    ],
)
logger = logging.getLogger(__name__)

def main():
    parser = argparse.ArgumentParser(description='ìŠ¤í¬ë¦½íŠ¸ ì„¤ëª…')
    # ê° ìŠ¤í¬ë¦½íŠ¸ë³„ ê³ ìœ  ì¸ìë“¤
    args = parser.parse_args()
    
    try:
        logger.info(f"ìŠ¤í¬ë¦½íŠ¸ ì‹œì‘: {__name__}")
        
        # í™˜ê²½ë³€ìˆ˜ ê²€ì¦
        if not settings.validate():
            logger.error("í•„ìˆ˜ í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
            sys.exit(1)
        
        # ë©”ì¸ ë¡œì§
        logger.info("ìŠ¤í¬ë¦½íŠ¸ ì™„ë£Œ")
    except Exception as e:
        logger.error(f"ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {e}")
        sys.exit(1)

if __name__ == "__main__":
    main()
```

## ğŸ”„ êµ¬í˜„ëœ ìŠ¤í¬ë¦½íŠ¸ë“¤

### 1. crawl_news.py âœ… êµ¬í˜„ì™„ë£Œ
```bash
python scripts/crawl_news.py --date 2024-01-15
python scripts/crawl_news.py --date 2024-01-15 --dry-run
python scripts/crawl_news.py --date 2024-01-15 --keywords ì¶©ê²© ë°˜ì „ --max-per-keyword 50
```

**êµ¬í˜„ëœ ê¸°ëŠ¥:**
- ë‚ ì§œ íŒŒë¼ë¯¸í„° ê²€ì¦ (í•„ìˆ˜, ìµœê·¼ 3ê°œì›” ì´ë‚´)
- ê¸°ë³¸ í‚¤ì›Œë“œ ë˜ëŠ” ì»¤ìŠ¤í…€ í‚¤ì›Œë“œ ì§€ì›
- Dry-run ëª¨ë“œ (ì‹¤ì œ ì €ì¥ ì—†ì´ í…ŒìŠ¤íŠ¸)
- ì¤‘ë³µ ì²´í¬ ë° ë°ì´í„° ê²€ì¦
- Supabase ì €ì¥
- ìƒì„¸í•œ ë¡œê¹… ë° ì„±ëŠ¥ ì¶”ì 

**ì£¼ìš” íŒŒë¼ë¯¸í„°:**
- `--date`: í¬ë¡¤ë§ ë‚ ì§œ (YYYY-MM-DD, í•„ìˆ˜)
- `--keywords`: ê²€ìƒ‰ í‚¤ì›Œë“œ ëª©ë¡ (ê¸°ë³¸ê°’: settings.DEFAULT_KEYWORDS)
- `--max-per-keyword`: í‚¤ì›Œë“œë‹¹ ìµœëŒ€ ê¸°ì‚¬ ìˆ˜ (ê¸°ë³¸ê°’: 100)
- `--dry-run`: í…ŒìŠ¤íŠ¸ ëª¨ë“œ (ì €ì¥ ì•ˆí•¨)

### 2. sync_journalist_stats.py âœ… êµ¬í˜„ì™„ë£Œ
```bash
python scripts/sync_journalist_stats.py
python scripts/sync_journalist_stats.py --fix-inconsistencies
python scripts/sync_journalist_stats.py --full-update
python scripts/sync_journalist_stats.py --log-level DEBUG
```

**êµ¬í˜„ëœ ê¸°ëŠ¥:**
- ê¸°ì í†µê³„ ìë™ ë™ê¸°í™”
- í†µê³„ ë¶ˆì¼ì¹˜ ê°ì§€ ë° ìˆ˜ì •
- ì „ì²´ ê¸°ì í†µê³„ ê°•ì œ ì—…ë°ì´íŠ¸
- ìƒì„¸í•œ ê²°ê³¼ ìš”ì•½ ì¶œë ¥
- ì‹¤í–‰ ê²°ê³¼ ì„±ëŠ¥ ì¶”ì 

**ì£¼ìš” íŒŒë¼ë¯¸í„°:**
- `--log-level`: ë¡œê·¸ ë ˆë²¨ ì„¤ì • (DEBUG, INFO, WARNING, ERROR)
- `--fix-inconsistencies`: í†µê³„ ë¶ˆì¼ì¹˜ ìˆ˜ì • (ê¸°ë³¸ê°’: True)
- `--no-fix-inconsistencies`: í†µê³„ ë¶ˆì¼ì¹˜ ìˆ˜ì • ë¹„í™œì„±í™”
- `--full-update`: ëª¨ë“  ê¸°ì í†µê³„ ê°•ì œ ì—…ë°ì´íŠ¸
- `--quiet`: ìš”ì•½ ì¶œë ¥ ìƒëµ

## ğŸš§ ë¯¸êµ¬í˜„ ìŠ¤í¬ë¦½íŠ¸ë“¤ (í–¥í›„ ê°œë°œ ì˜ˆì •)

### 3. process_openai_batch.py âŒ ë¯¸êµ¬í˜„
```bash
# í–¥í›„ êµ¬í˜„ ì˜ˆì •
python scripts/process_openai_batch.py --create-batch
python scripts/process_openai_batch.py --batch-id batch_abc123
```

**ê³„íšëœ ê¸°ëŠ¥:**
- ë¯¸ì²˜ë¦¬ ê¸°ì‚¬ ì¡°íšŒ
- OpenAI Batch API ìš”ì²­ ìƒì„±
- ë°°ì¹˜ ìƒíƒœ ì¶”ì 

### 4. monitor_batches.py âŒ ë¯¸êµ¬í˜„
```bash
# í–¥í›„ êµ¬í˜„ ì˜ˆì •
python scripts/monitor_batches.py --check-all
python scripts/monitor_batches.py --batch-id batch_abc123
```

**ê³„íšëœ ê¸°ëŠ¥:**
- ì§„í–‰ì¤‘ì¸ ë°°ì¹˜ ìƒíƒœ í™•ì¸
- ì™„ë£Œëœ ë°°ì¹˜ ì•Œë¦¼
- ì‹¤íŒ¨í•œ ë°°ì¹˜ ì¬ì‹œë„

### 5. process_completed_batches.py âŒ ë¯¸êµ¬í˜„
```bash
# í–¥í›„ êµ¬í˜„ ì˜ˆì •
python scripts/process_completed_batches.py --batch-id batch_abc123
python scripts/process_completed_batches.py --auto-process
```

**ê³„íšëœ ê¸°ëŠ¥:**
- ì™„ë£Œëœ ë°°ì¹˜ ê²°ê³¼ ë‹¤ìš´ë¡œë“œ
- ì‘ë‹µ íŒŒì‹± ë° ì ìˆ˜ ì¶”ì¶œ
- ê¸°ì‚¬ ë°ì´í„° ì—…ë°ì´íŠ¸

## ğŸ“Š ë¡œê¹… ë° ëª¨ë‹ˆí„°ë§ âœ… êµ¬í˜„ì™„ë£Œ

### ë¡œê·¸ ë ˆë²¨ ì •ì˜
- **DEBUG**: ìƒì„¸í•œ ë””ë²„ê¹… ì •ë³´
- **INFO**: ì¼ë°˜ì ì¸ ì‹¤í–‰ ì •ë³´ (ê¸°ë³¸ê°’)
- **WARNING**: ê²½ê³  ë©”ì‹œì§€
- **ERROR**: ì˜¤ë¥˜ ë°œìƒ
- **CRITICAL**: ì¹˜ëª…ì ì¸ ì˜¤ë¥˜

### ë¡œê·¸ í¬ë§· âœ… êµ¬í˜„ì™„ë£Œ
```
2024-01-15 10:30:45 - crawl_news - INFO - í¬ë¡¤ë§ ì‹œì‘: 2024-01-15
2024-01-15 10:30:47 - crawl_news - INFO - ì²˜ë¦¬ëœ ê¸°ì‚¬ ìˆ˜: 150
2024-01-15 10:30:48 - crawl_news - WARNING - ì¤‘ë³µ ê¸°ì‚¬ ìŠ¤í‚µ: 5ê°œ
2024-01-15 10:30:50 - crawl_news - INFO - í¬ë¡¤ë§ ì™„ë£Œ: 2024-01-15
```

### ë¡œê·¸ íŒŒì¼ ê´€ë¦¬ âœ… êµ¬í˜„ì™„ë£Œ
- ì¼ë³„ ë¡œê·¸ íŒŒì¼ ìë™ ìƒì„±: `logs/{ìŠ¤í¬ë¦½íŠ¸ëª…}_YYYYMMDD.log`
- ì½˜ì†”ê³¼ íŒŒì¼ ë™ì‹œ ì¶œë ¥
- UTF-8 ì¸ì½”ë”© ì§€ì›
- logs ë””ë ‰í† ë¦¬ ìë™ ìƒì„±

### ì„±ëŠ¥ ì§€í‘œ ì¶”ì  âœ… êµ¬í˜„ì™„ë£Œ
```python
# sync_journalist_stats.pyì—ì„œ êµ¬í˜„ë¨
def print_result_summary(result: dict):
    """ì‹¤í–‰ ê²°ê³¼ ìš”ì•½ ì¶œë ¥"""
    start_time = datetime.fromisoformat(result["start_time"])
    end_time = datetime.fromisoformat(result["end_time"])
    duration = end_time - start_time
    
    print(f"ğŸ• ì‹¤í–‰ ì‹œê°„: {duration.total_seconds():.2f}ì´ˆ")
    print(f"âœ… ì„±ê³µ ì—¬ë¶€: {'ì„±ê³µ' if result['success'] else 'ì‹¤íŒ¨'}")
    # ìƒì„¸ í†µê³„ ì¶œë ¥...
```

## ğŸ› ï¸ ì—ëŸ¬ í•¸ë“¤ë§ âœ… êµ¬í˜„ì™„ë£Œ

### í™˜ê²½ë³€ìˆ˜ ê²€ì¦ âœ… êµ¬í˜„ì™„ë£Œ
```python
# ëª¨ë“  ìŠ¤í¬ë¦½íŠ¸ì—ì„œ ê³µí†µ ì ìš©
if not settings.validate():
    logger.error("í•„ìˆ˜ í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
    logger.error("SUPABASE_URL, SUPABASE_SERVICE_ROLE_KEY, NAVER_CLIENT_ID, NAVER_CLIENT_SECRETì´ í•„ìš”í•©ë‹ˆë‹¤")
    sys.exit(1)
```

### ì˜ˆì™¸ ì²˜ë¦¬ âœ… êµ¬í˜„ì™„ë£Œ
```python
try:
    # ë©”ì¸ ë¡œì§ ì‹¤í–‰
    logger.info("ìŠ¤í¬ë¦½íŠ¸ ì™„ë£Œ")
except ValueError as e:
    logger.error(f"ì…ë ¥ê°’ ì˜¤ë¥˜: {e}")
    sys.exit(1)
except Exception as e:
    logger.error(f"ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {e}")
    sys.exit(1)
```

### ì¬ì‹œë„ ë©”ì»¤ë‹ˆì¦˜ âŒ ë¯¸êµ¬í˜„ (í–¥í›„ ì¶”ê°€ ì˜ˆì •)
```python
# í–¥í›„ êµ¬í˜„ ì˜ˆì •
import time
import random

def retry_with_backoff(max_retries=3, base_delay=1, max_delay=60):
    def decorator(func):
        @wraps(func)
        def wrapper(*args, **kwargs):
            for attempt in range(max_retries):
                try:
                    return func(*args, **kwargs)
                except Exception as e:
                    if attempt == max_retries - 1:
                        logger.error(f"ìµœì¢… ì‹¤íŒ¨: {e}")
                        raise
                    
                    delay = min(base_delay * (2 ** attempt) + random.uniform(0, 1), max_delay)
                    logger.warning(f"ì¬ì‹œë„ {attempt + 1}/{max_retries} in {delay:.2f}ì´ˆ: {e}")
                    time.sleep(delay)
        return wrapper
    return decorator
```

## ğŸ”’ ë³´ì•ˆ ë° ì„¤ì • âœ… êµ¬í˜„ì™„ë£Œ

### í™˜ê²½ ë³€ìˆ˜ ê´€ë¦¬
```python
# src/config/settings.pyì—ì„œ ì¤‘ì•™ ê´€ë¦¬
from src.config.settings import settings

REQUIRED_ENV_VARS = [
    'SUPABASE_URL',
    'SUPABASE_SERVICE_ROLE_KEY',
    'NAVER_CLIENT_ID',
    'NAVER_CLIENT_SECRET'
]

# ìë™ ê²€ì¦ ë¡œì§ í¬í•¨
def validate_environment():
    return settings.validate()
```

## ğŸ“… ìŠ¤ì¼€ì¤„ë§ âŒ ë¯¸êµ¬í˜„ (í–¥í›„ GitHub Actionsë¡œ êµ¬í˜„ ì˜ˆì •)

### Cron ì„¤ì • ì˜ˆì‹œ (ê³„íš)
```bash
# ë§¤ì¼ ì˜¤ì „ 9ì‹œ ë‰´ìŠ¤ í¬ë¡¤ë§
0 9 * * * /usr/bin/python3 /path/to/scripts/crawl_news.py --date $(date +\%Y-\%m-\%d)

# ë§¤ì¼ ìì • ê¸°ì í†µê³„ ë™ê¸°í™”
0 0 * * * /usr/bin/python3 /path/to/scripts/sync_journalist_stats.py
```

### GitHub Actions í†µí•© âŒ ë¯¸êµ¬í˜„ (í–¥í›„ êµ¬í˜„ ì˜ˆì •)
```yaml
# í–¥í›„ êµ¬í˜„ ì˜ˆì •
name: Daily News Crawling
on:
  schedule:
    - cron: '0 9 * * *'  # ë§¤ì¼ ì˜¤ì „ 9ì‹œ
  workflow_dispatch:

jobs:
  crawl:
    runs-on: ubuntu-latest
    steps:
      - name: Crawl News
        run: python scripts/crawl_news.py --date $(date +%Y-%m-%d)
```

## ğŸ“ˆ í˜„ì¬ êµ¬í˜„ ìƒíƒœ ìš”ì•½

### âœ… ì™„ë£Œëœ ìŠ¤í¬ë¦½íŠ¸
1. **crawl_news.py**: ë„¤ì´ë²„ ë‰´ìŠ¤ í¬ë¡¤ë§ (ì™„ì „ êµ¬í˜„)
2. **sync_journalist_stats.py**: ê¸°ì í†µê³„ ë™ê¸°í™” (ì™„ì „ êµ¬í˜„)

### âŒ ë¯¸êµ¬í˜„ ìŠ¤í¬ë¦½íŠ¸ (ìš°ì„ ìˆœìœ„ ìˆœ)
1. **process_openai_batch.py**: OpenAI ë°°ì¹˜ ìƒì„±
2. **monitor_batches.py**: ë°°ì¹˜ ìƒíƒœ ëª¨ë‹ˆí„°ë§  
3. **process_completed_batches.py**: ë°°ì¹˜ ê²°ê³¼ ì²˜ë¦¬
4. **backup_data.py**: ë°ì´í„° ë°±ì—…

### ğŸ”„ ê°œì„  ê³„íš
1. OpenAI Batch API í†µí•© ì™„ë£Œ
2. GitHub Actions ì›Œí¬í”Œë¡œìš° êµ¬í˜„
3. ê³ ê¸‰ ì—ëŸ¬ í•¸ë“¤ë§ ë° ì¬ì‹œë„ ë¡œì§
4. ì•Œë¦¼ ì‹œìŠ¤í…œ (ìŠ¬ë™, ì´ë©”ì¼) í†µí•©

      - name: Crawl News
                 run: python scripts/crawl_news.py --date $(date +%Y-%m-%d)
```
