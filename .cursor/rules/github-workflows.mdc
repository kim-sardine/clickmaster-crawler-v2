
# GitHub Actions ì›Œí¬í”Œë¡œìš° ìë™í™”

## ğŸš§ í˜„ì¬ êµ¬í˜„ ìƒíƒœ

### âŒ ë¯¸êµ¬í˜„ ë¶€ë¶„
- `.github/workflows/` ë””ë ‰í† ë¦¬ê°€ ë¹„ì–´ìˆìŒ
- ëª¨ë“  ì›Œí¬í”Œë¡œìš° íŒŒì¼ì´ ë¯¸êµ¬í˜„ ìƒíƒœ
- ìë™í™” íŒŒì´í”„ë¼ì¸ ë¯¸ì„¤ì •

### âœ… ì¤€ë¹„ëœ ë¶€ë¶„
- ë…ë¦½ ì‹¤í–‰ ê°€ëŠ¥í•œ ìŠ¤í¬ë¦½íŠ¸ë“¤ êµ¬í˜„ì™„ë£Œ
- í™˜ê²½ë³€ìˆ˜ ê´€ë¦¬ ì‹œìŠ¤í…œ êµ¬ì¶•
- ë¡œê¹… ì‹œìŠ¤í…œ ì™„ë¹„

## ğŸš€ ì›Œí¬í”Œë¡œìš° ê°œìš” (êµ¬í˜„ ì˜ˆì •)

### ìë™í™” íŒŒì´í”„ë¼ì¸ ê³„íš
1. **ë§¤ì¼ ë‰´ìŠ¤ í¬ë¡¤ë§** - ì˜¤ì „ 9ì‹œ ìë™ ì‹¤í–‰ (âœ… ìŠ¤í¬ë¦½íŠ¸ ì¤€ë¹„ì™„ë£Œ)
2. **ë°°ì¹˜ ì²˜ë¦¬ ëª¨ë‹ˆí„°ë§** - 10ë¶„ë§ˆë‹¤ ìƒíƒœ í™•ì¸ (âŒ ìŠ¤í¬ë¦½íŠ¸ ë¯¸êµ¬í˜„)
3. **ì™„ë£Œëœ ë°°ì¹˜ ì²˜ë¦¬** - 30ë¶„ë§ˆë‹¤ ê²°ê³¼ ì²˜ë¦¬ (âŒ ìŠ¤í¬ë¦½íŠ¸ ë¯¸êµ¬í˜„)
4. **ê¸°ì í†µê³„ ë™ê¸°í™”** - ë§¤ì¼ ìì • ì‹¤í–‰ (âœ… ìŠ¤í¬ë¦½íŠ¸ ì¤€ë¹„ì™„ë£Œ)

### ì›Œí¬í”Œë¡œìš° êµ¬ì¡° (ê³„íš)
```
.github/workflows/
â”œâ”€â”€ daily-crawler.yml          # ë§¤ì¼ ë‰´ìŠ¤ í¬ë¡¤ë§ (ë¯¸êµ¬í˜„)
â”œâ”€â”€ batch-processor.yml        # ë°°ì¹˜ ì²˜ë¦¬ ëª¨ë‹ˆí„°ë§ (ë¯¸êµ¬í˜„)
â”œâ”€â”€ sync-stats.yml            # ê¸°ì í†µê³„ ë™ê¸°í™” (ë¯¸êµ¬í˜„)
â””â”€â”€ manual-trigger.yml        # ìˆ˜ë™ ì‹¤í–‰ ì›Œí¬í”Œë¡œìš° (ë¯¸êµ¬í˜„)
```

## ğŸ“… ìŠ¤ì¼€ì¤„ë§ ì›Œí¬í”Œë¡œìš° (êµ¬í˜„ ì˜ˆì •)

### ë§¤ì¼ ë‰´ìŠ¤ í¬ë¡¤ë§ (ë¯¸êµ¬í˜„)
```yaml
# .github/workflows/daily-crawler.yml (ë¯¸êµ¬í˜„)
name: Daily News Crawling
on:
  schedule:
    - cron: '0 9 * * *'  # ë§¤ì¼ ì˜¤ì „ 9ì‹œ (UTC)
  workflow_dispatch:     # ìˆ˜ë™ ì‹¤í–‰ ê°€ëŠ¥

jobs:
  crawl-naver-api:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      
      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.9'
          
      - name: Install dependencies
        run: |
          pip install -r requirements.txt
          
      - name: Crawl Naver News
        env:
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_SERVICE_ROLE_KEY: ${{ secrets.SUPABASE_SERVICE_ROLE_KEY }}
          NAVER_CLIENT_ID: ${{ secrets.NAVER_CLIENT_ID }}
          NAVER_CLIENT_SECRET: ${{ secrets.NAVER_CLIENT_SECRET }}
        run: |
          python scripts/crawl_news.py --date $(date +%Y-%m-%d)
          
      - name: Notify Results
        if: always()
        run: |
          echo "í¬ë¡¤ë§ ì™„ë£Œ: $(date)"
```

### ê¸°ì í†µê³„ ë™ê¸°í™” (ë¯¸êµ¬í˜„)
```yaml
# .github/workflows/sync-stats.yml (ë¯¸êµ¬í˜„)
name: Sync Journalist Stats
on:
  schedule:
    - cron: '0 0 * * *'  # ë§¤ì¼ ìì • (UTC)
  workflow_dispatch:

jobs:
  sync-stats:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      
      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.9'
          
      - name: Install dependencies
        run: pip install -r requirements.txt
        
      - name: Sync Journalist Statistics
        env:
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_SERVICE_ROLE_KEY: ${{ secrets.SUPABASE_SERVICE_ROLE_KEY }}
        run: |
          python scripts/sync_journalist_stats.py --fix-inconsistencies
```

### ë°°ì¹˜ ì²˜ë¦¬ ëª¨ë‹ˆí„°ë§ (ë¯¸êµ¬í˜„ - OpenAI êµ¬í˜„ í›„)
```yaml
# .github/workflows/batch-processor.yml (ë¯¸êµ¬í˜„)
name: Batch Processing Monitor
on:
  schedule:
    - cron: '*/10 * * * *'  # 10ë¶„ë§ˆë‹¤ ì‹¤í–‰
  workflow_dispatch:

jobs:
  monitor-batches:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      
      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.9'
          
      - name: Install dependencies
        run: pip install -r requirements.txt
        
      - name: Monitor Active Batches
        env:
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_SERVICE_ROLE_KEY: ${{ secrets.SUPABASE_SERVICE_ROLE_KEY }}
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
        run: |
          python scripts/monitor_batches.py --check-all
          
      - name: Process Completed Batches
        env:
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_SERVICE_ROLE_KEY: ${{ secrets.SUPABASE_SERVICE_ROLE_KEY }}
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
        run: |
          python scripts/process_completed_batches.py --auto-process
```

## ğŸ”§ ìˆ˜ë™ ì‹¤í–‰ ì›Œí¬í”Œë¡œìš° (êµ¬í˜„ ì˜ˆì •)

### ìˆ˜ë™ íŠ¸ë¦¬ê±° (ë¯¸êµ¬í˜„)
```yaml
# .github/workflows/manual-trigger.yml (ë¯¸êµ¬í˜„)
name: Manual Operations
on:
  workflow_dispatch:
    inputs:
      operation:
        description: 'ì‹¤í–‰í•  ì‘ì—… ì„ íƒ'
        required: true
        default: 'crawl'
        type: choice
        options:
          - crawl
          - sync-stats
          - batch-create
          - batch-monitor
          - batch-process
          
      date:
        description: 'ì²˜ë¦¬ ë‚ ì§œ (YYYY-MM-DD)'
        required: false
        type: string
        
      dry_run:
        description: 'í…ŒìŠ¤íŠ¸ ëª¨ë“œ (ì‹¤ì œ ì €ì¥ ì•ˆí•¨)'
        required: false
        default: false
        type: boolean

jobs:
  manual-operation:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      
      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.9'
          
      - name: Install dependencies
        run: pip install -r requirements.txt
        
      - name: Execute Selected Operation
        env:
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_SERVICE_ROLE_KEY: ${{ secrets.SUPABASE_SERVICE_ROLE_KEY }}
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
          NAVER_CLIENT_ID: ${{ secrets.NAVER_CLIENT_ID }}
          NAVER_CLIENT_SECRET: ${{ secrets.NAVER_CLIENT_SECRET }}
        run: |
          case "${{ github.event.inputs.operation }}" in
            crawl)
              if [ "${{ github.event.inputs.dry_run }}" = "true" ]; then
                python scripts/crawl_news.py --date "${{ github.event.inputs.date }}" --dry-run
              else
                python scripts/crawl_news.py --date "${{ github.event.inputs.date }}"
              fi
              ;;
            sync-stats)
              python scripts/sync_journalist_stats.py --fix-inconsistencies
              ;;
            batch-create)
              python scripts/process_openai_batch.py --create-batch
              ;;
            batch-monitor)
              python scripts/monitor_batches.py --check-all
              ;;
            batch-process)
              python scripts/process_completed_batches.py --auto-process
              ;;
          esac
```

## ğŸ”’ ë³´ì•ˆ ë° Secrets ê´€ë¦¬

### í•„ìˆ˜ Secrets (ì„¤ì • í•„ìš”)
```yaml
secrets:
  SUPABASE_URL: "https://your-project.supabase.co"
  SUPABASE_SERVICE_ROLE_KEY: "your-supabase-service-role-key"
  OPENAI_API_KEY: "sk-your-openai-api-key"  # í–¥í›„ ì¶”ê°€
  NAVER_CLIENT_ID: "your-naver-client-id"
  NAVER_CLIENT_SECRET: "your-naver-client-secret"
  SLACK_WEBHOOK_URL: "https://hooks.slack.com/services/..."  # ì„ íƒì‚¬í•­
```

### í™˜ê²½ ë³€ìˆ˜ ê²€ì¦ (êµ¬í˜„ ì˜ˆì •)
```yaml
- name: Validate Environment
  run: |
    if [ -z "$SUPABASE_URL" ]; then
      echo "SUPABASE_URLì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
      exit 1
    fi
    if [ -z "$SUPABASE_SERVICE_ROLE_KEY" ]; then
      echo "SUPABASE_SERVICE_ROLE_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
      exit 1
    fi
    if [ -z "$NAVER_CLIENT_ID" ]; then
      echo "NAVER_CLIENT_IDê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
      exit 1
    fi
```

## ğŸ“Š ëª¨ë‹ˆí„°ë§ ë° ì•Œë¦¼ (êµ¬í˜„ ì˜ˆì •)

### ì‹¤í–‰ ê²°ê³¼ ì•Œë¦¼ (ë¯¸êµ¬í˜„)
```yaml
- name: Slack Notification
  if: always()
  uses: 8398a7/action-slack@v3
  with:
    status: ${{ job.status }}
    channel: '#news-crawler'
    webhook_url: ${{ secrets.SLACK_WEBHOOK_URL }}
    fields: repo,message,commit,author,action,eventName,ref,workflow
```

### ì—ëŸ¬ í•¸ë“¤ë§ (êµ¬í˜„ ì˜ˆì •)
```yaml
- name: Handle Errors
  if: failure()
  run: |
    echo "ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
    echo "ë¡œê·¸ë¥¼ í™•ì¸í•˜ì—¬ ë¬¸ì œë¥¼ í•´ê²°í•˜ì„¸ìš”."
    # ì—ëŸ¬ ë¡œê·¸ ìˆ˜ì§‘ ë° ì „ì†¡
```

## ğŸ”„ ì›Œí¬í”Œë¡œìš° ìµœì í™” (êµ¬í˜„ ì˜ˆì •)

### ìºì‹± ì „ëµ
```yaml
- name: Cache Dependencies
  uses: actions/cache@v3
  with:
    path: ~/.cache/pip
    key: ${{ runner.os }}-pip-${{ hashFiles('requirements.txt') }}
    restore-keys: |
      ${{ runner.os }}-pip-
```

### ë³‘ë ¬ ì²˜ë¦¬ (í–¥í›„ ê³ ë ¤)
```yaml
strategy:
  matrix:
    date_offset: [0, 1, 2]  # ìµœê·¼ 3ì¼ê°„ ë³‘ë ¬ í¬ë¡¤ë§
    
steps:
  - name: Crawl News (Day -${{ matrix.date_offset }})
    run: |
      target_date=$(date -d "${{ matrix.date_offset }} days ago" +%Y-%m-%d)
      python scripts/crawl_news.py --date $target_date
```

## ğŸ“ˆ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ (êµ¬í˜„ ì˜ˆì •)

### ì‹¤í–‰ ì‹œê°„ ì¶”ì 
```yaml
- name: Track Execution Time
  run: |
    start_time=$(date +%s)
    python scripts/crawl_news.py --date $(date +%Y-%m-%d)
    end_time=$(date +%s)
    echo "ì‹¤í–‰ ì‹œê°„: $((end_time - start_time))ì´ˆ"
```

### ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ëŸ‰ ëª¨ë‹ˆí„°ë§
```yaml
- name: Monitor Resources
  run: |
    echo "ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰:"
    free -h
    echo "ë””ìŠ¤í¬ ì‚¬ìš©ëŸ‰:"
    df -h
```

## ğŸš€ ë°°í¬ ë° ë¦´ë¦¬ìŠ¤ (êµ¬í˜„ ì˜ˆì •)

### íƒœê·¸ ê¸°ë°˜ ë°°í¬
```yaml
# .github/workflows/release.yml (ë¯¸êµ¬í˜„)
name: Release
on:
  push:
    tags:
      - 'v*'

jobs:
  release:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      
      - name: Create Release
        uses: actions/create-release@v1
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        with:
          tag_name: ${{ github.ref }}
          release_name: Release ${{ github.ref }}
          draft: false
          prerelease: false
```

## ğŸ“‹ êµ¬í˜„ ìš°ì„ ìˆœìœ„

### Phase 1: ê¸°ë³¸ ìë™í™” (ì¦‰ì‹œ êµ¬í˜„ ê°€ëŠ¥)
1. âœ… **daily-crawler.yml**: ë§¤ì¼ ë‰´ìŠ¤ í¬ë¡¤ë§ (ìŠ¤í¬ë¦½íŠ¸ ì¤€ë¹„ì™„ë£Œ)
2. âœ… **sync-stats.yml**: ê¸°ì í†µê³„ ë™ê¸°í™” (ìŠ¤í¬ë¦½íŠ¸ ì¤€ë¹„ì™„ë£Œ)
3. âœ… **manual-trigger.yml**: ìˆ˜ë™ ì‹¤í–‰ (ê¸°ë³¸ ì‘ì—…ë“¤)

### Phase 2: OpenAI í†µí•© í›„ (ìŠ¤í¬ë¦½íŠ¸ êµ¬í˜„ í•„ìš”)
1. âŒ **batch-processor.yml**: ë°°ì¹˜ ì²˜ë¦¬ ëª¨ë‹ˆí„°ë§
2. âŒ **manual-trigger.yml**: OpenAI ê´€ë ¨ ì‘ì—… ì¶”ê°€

### Phase 3: ê³ ê¸‰ ê¸°ëŠ¥ (ì„ íƒì‚¬í•­)
1. ì•Œë¦¼ ì‹œìŠ¤í…œ í†µí•©
2. ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§
3. ìë™ ë¦´ë¦¬ìŠ¤

## ğŸ”§ í˜„ì¬ ì‹¤í–‰ ê°€ëŠ¥í•œ ëŒ€ì•ˆ

### ë¡œì»¬ Cron ì„¤ì • (ì„ì‹œ ëŒ€ì•ˆ)
```bash
# crontab -e
# ë§¤ì¼ ì˜¤ì „ 9ì‹œ ë‰´ìŠ¤ í¬ë¡¤ë§
0 9 * * * cd /path/to/clickmaster-crawler && python scripts/crawl_news.py --date $(date +\%Y-\%m-\%d)

# ë§¤ì¼ ìì • ê¸°ì í†µê³„ ë™ê¸°í™”  
0 0 * * * cd /path/to/clickmaster-crawler && python scripts/sync_journalist_stats.py
```

### ìˆ˜ë™ ì‹¤í–‰ (í˜„ì¬ ì‚¬ìš© ê°€ëŠ¥)
```bash
# ë‰´ìŠ¤ í¬ë¡¤ë§
python scripts/crawl_news.py --date 2024-01-15

# ê¸°ì í†µê³„ ë™ê¸°í™”
python scripts/sync_journalist_stats.py

# í…ŒìŠ¤íŠ¸ ëª¨ë“œ
python scripts/crawl_news.py --date 2024-01-15 --dry-run
```

## ğŸ¯ ë‹¤ìŒ ë‹¨ê³„

1. **ì¦‰ì‹œ êµ¬í˜„**: `daily-crawler.yml`, `sync-stats.yml` ìƒì„±
2. **OpenAI í†µí•©**: ë°°ì¹˜ ì²˜ë¦¬ ìŠ¤í¬ë¦½íŠ¸ ì™„ì„± í›„ `batch-processor.yml` ì¶”ê°€
3. **ê³ ë„í™”**: ì•Œë¦¼, ëª¨ë‹ˆí„°ë§, ì—ëŸ¬ í•¸ë“¤ë§ ê°•í™”

    echo "ë””ìŠ¤í¬ ì‚¬ìš©ëŸ‰:"
         df -h
```
