---
globs: ".github/workflows/*"
description: "GitHub Actions ì›Œí¬í”Œë¡œìš° ìë™í™” ê°€ì´ë“œ"
---

# GitHub Actions ì›Œí¬í”Œë¡œìš° ìë™í™”

## ğŸš€ ì›Œí¬í”Œë¡œìš° ê°œìš”

### ìë™í™” íŒŒì´í”„ë¼ì¸
1. **ë§¤ì¼ ë‰´ìŠ¤ í¬ë¡¤ë§** - ì˜¤ì „ 9ì‹œ ìë™ ì‹¤í–‰
2. **ë°°ì¹˜ ì²˜ë¦¬ ëª¨ë‹ˆí„°ë§** - 10ë¶„ë§ˆë‹¤ ìƒíƒœ í™•ì¸
3. **ì™„ë£Œëœ ë°°ì¹˜ ì²˜ë¦¬** - 30ë¶„ë§ˆë‹¤ ê²°ê³¼ ì²˜ë¦¬
4. **ë°ì´í„° ë°±ì—…** - ë§¤ì¼ ìì • ë°±ì—…

### ì›Œí¬í”Œë¡œìš° êµ¬ì¡°
```
.github/workflows/
â”œâ”€â”€ daily-crawler.yml          # ë§¤ì¼ ë‰´ìŠ¤ í¬ë¡¤ë§
â”œâ”€â”€ batch-processor.yml        # ë°°ì¹˜ ì²˜ë¦¬ ëª¨ë‹ˆí„°ë§
â”œâ”€â”€ data-backup.yml           # ë°ì´í„° ë°±ì—…
â””â”€â”€ manual-trigger.yml        # ìˆ˜ë™ ì‹¤í–‰ ì›Œí¬í”Œë¡œìš°
```

## ğŸ“… ìŠ¤ì¼€ì¤„ë§ ì›Œí¬í”Œë¡œìš°

### ë§¤ì¼ ë‰´ìŠ¤ í¬ë¡¤ë§
```yaml
name: Daily News Crawling
on:
  schedule:
    - cron: '0 9 * * *'  # ë§¤ì¼ ì˜¤ì „ 9ì‹œ (UTC)
  workflow_dispatch:     # ìˆ˜ë™ ì‹¤í–‰ ê°€ëŠ¥

jobs:
  crawl-naver-api:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      
      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.9'
          
      - name: Install dependencies
        run: |
          pip install -r requirements.txt
          
      - name: Crawl Naver API
        env:
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_SERVICE_ROLE_KEY: ${{ secrets.SUPABASE_SERVICE_ROLE_KEY }}
          NAVER_CLIENT_ID: ${{ secrets.NAVER_CLIENT_ID }}
          NAVER_CLIENT_SECRET: ${{ secrets.NAVER_CLIENT_SECRET }}
        run: |
          python scripts/crawl_news.py --date $(date +%Y-%m-%d) --source api
          
      - name: Crawl Naver Entertainment
        env:
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_SERVICE_ROLE_KEY: ${{ secrets.SUPABASE_SERVICE_ROLE_KEY }}
        run: |
          python scripts/crawl_news.py --date $(date +%Y-%m-%d) --source entertain
          
      - name: Notify Results
        if: always()
        run: |
          echo "í¬ë¡¤ë§ ì™„ë£Œ: $(date)"
```

### ë°°ì¹˜ ì²˜ë¦¬ ëª¨ë‹ˆí„°ë§
```yaml
name: Batch Processing Monitor
on:
  schedule:
    - cron: '*/10 * * * *'  # 10ë¶„ë§ˆë‹¤ ì‹¤í–‰
  workflow_dispatch:

jobs:
  monitor-batches:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      
      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.9'
          
      - name: Install dependencies
        run: pip install -r requirements.txt
        
      - name: Monitor Active Batches
        env:
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_SERVICE_ROLE_KEY: ${{ secrets.SUPABASE_SERVICE_ROLE_KEY }}
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
        run: |
          python scripts/monitor_batches.py --check-all
          
      - name: Process Completed Batches
        env:
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_SERVICE_ROLE_KEY: ${{ secrets.SUPABASE_SERVICE_ROLE_KEY }}
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
        run: |
          python scripts/process_completed_batches.py --auto-process
```

## ğŸ”§ ìˆ˜ë™ ì‹¤í–‰ ì›Œí¬í”Œë¡œìš°

### ìˆ˜ë™ íŠ¸ë¦¬ê±°
```yaml
name: Manual Operations
on:
  workflow_dispatch:
    inputs:
      operation:
        description: 'ì‹¤í–‰í•  ì‘ì—… ì„ íƒ'
        required: true
        default: 'crawl'
        type: choice
        options:
          - crawl
          - batch-create
          - batch-monitor
          - batch-process
          - data-backup
          
      date:
        description: 'ì²˜ë¦¬ ë‚ ì§œ (YYYY-MM-DD)'
        required: false
        type: string
        
      source:
        description: 'í¬ë¡¤ë§ ì†ŒìŠ¤ (api/entertain)'
        required: false
        default: 'api'
        type: choice
        options:
          - api
          - entertain

jobs:
  manual-operation:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      
      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.9'
          
      - name: Install dependencies
        run: pip install -r requirements.txt
        
      - name: Execute Selected Operation
        env:
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_SERVICE_ROLE_KEY: ${{ secrets.SUPABASE_SERVICE_ROLE_KEY }}
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
          NAVER_CLIENT_ID: ${{ secrets.NAVER_CLIENT_ID }}
          NAVER_CLIENT_SECRET: ${{ secrets.NAVER_CLIENT_SECRET }}
        run: |
          case "${{ github.event.inputs.operation }}" in
            crawl)
              python scripts/crawl_news.py --date "${{ github.event.inputs.date }}" --source "${{ github.event.inputs.source }}"
              ;;
            batch-create)
              python scripts/process_openai_batch.py --create-batch
              ;;
            batch-monitor)
              python scripts/monitor_batches.py --check-all
              ;;
            batch-process)
              python scripts/process_completed_batches.py --auto-process
              ;;
            data-backup)
              python scripts/backup_data.py --date "${{ github.event.inputs.date }}"
              ;;
          esac
```

## ğŸ”’ ë³´ì•ˆ ë° Secrets ê´€ë¦¬

### í•„ìˆ˜ Secrets
```yaml
secrets:
  SUPABASE_URL: "https://your-project.supabase.co"
  SUPABASE_SERVICE_ROLE_KEY: "your-supabase-service-role-key"
  OPENAI_API_KEY: "sk-your-openai-api-key"
  NAVER_CLIENT_ID: "your-naver-client-id"
  NAVER_CLIENT_SECRET: "your-naver-client-secret"
  SLACK_WEBHOOK_URL: "https://hooks.slack.com/services/..."  # ì„ íƒì‚¬í•­
```

### í™˜ê²½ ë³€ìˆ˜ ê²€ì¦
```yaml
- name: Validate Environment
  run: |
    if [ -z "$SUPABASE_URL" ]; then
      echo "SUPABASE_URLì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
      exit 1
    fi
    if [ -z "$OPENAI_API_KEY" ]; then
      echo "OPENAI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
      exit 1
    fi
```

## ğŸ“Š ëª¨ë‹ˆí„°ë§ ë° ì•Œë¦¼

### ì‹¤í–‰ ê²°ê³¼ ì•Œë¦¼
```yaml
- name: Slack Notification
  if: always()
  uses: 8398a7/action-slack@v3
  with:
    status: ${{ job.status }}
    channel: '#news-crawler'
    webhook_url: ${{ secrets.SLACK_WEBHOOK_URL }}
    fields: repo,message,commit,author,action,eventName,ref,workflow
```

### ì—ëŸ¬ í•¸ë“¤ë§
```yaml
- name: Handle Errors
  if: failure()
  run: |
    echo "ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
    echo "ë¡œê·¸ë¥¼ í™•ì¸í•˜ì—¬ ë¬¸ì œë¥¼ í•´ê²°í•˜ì„¸ìš”."
    # ì—ëŸ¬ ë¡œê·¸ ìˆ˜ì§‘ ë° ì „ì†¡
```

## ğŸš€ ë°°í¬ ë° ë¦´ë¦¬ìŠ¤

### íƒœê·¸ ê¸°ë°˜ ë°°í¬
```yaml
name: Release
on:
  push:
    tags:
      - 'v*'

jobs:
  release:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      
      - name: Create Release
        uses: actions/create-release@v1
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        with:
          tag_name: ${{ github.ref }}
          release_name: Release ${{ github.ref }}
          draft: false
          prerelease: false
```

## ğŸ”„ ì›Œí¬í”Œë¡œìš° ìµœì í™”

### ìºì‹± ì „ëµ
```yaml
- name: Cache Dependencies
  uses: actions/cache@v3
  with:
    path: ~/.cache/pip
    key: ${{ runner.os }}-pip-${{ hashFiles('requirements.txt') }}
    restore-keys: |
      ${{ runner.os }}-pip-
```

### ë³‘ë ¬ ì²˜ë¦¬
```yaml
strategy:
  matrix:
    source: [api, entertain]
    
steps:
  - name: Crawl News (${{ matrix.source }})
    run: |
      python scripts/crawl_news.py --source ${{ matrix.source }}
```

## ğŸ“ˆ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§

### ì‹¤í–‰ ì‹œê°„ ì¶”ì 
```yaml
- name: Track Execution Time
  run: |
    start_time=$(date +%s)
    python scripts/crawl_news.py --date $(date +%Y-%m-%d)
    end_time=$(date +%s)
    echo "ì‹¤í–‰ ì‹œê°„: $((end_time - start_time))ì´ˆ"
```

### ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ëŸ‰ ëª¨ë‹ˆí„°ë§
```yaml
- name: Monitor Resources
  run: |
    echo "ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰:"
    free -h
    echo "ë””ìŠ¤í¬ ì‚¬ìš©ëŸ‰:"
         df -h
```
