# í´ë¦­ë§ˆìŠ¤í„° í¬ë¡¤ëŸ¬ (Clickmaster Crawler)

ë„¤ì´ë²„ ë‰´ìŠ¤ë¥¼ í¬ë¡¤ë§í•˜ì—¬ ê° ë‰´ìŠ¤ì˜ **Clickbait ì •ë„ë¥¼ 0~100 ì •ìˆ˜ ê°’ìœ¼ë¡œ ì¸¡ì •**í•˜ê³ , íŒë‹¨ ê·¼ê±°ì™€ í•¨ê»˜ Supabase ë°ì´í„°ë² ì´ìŠ¤ì— ì €ìž¥í•˜ëŠ” ì‹œìŠ¤í…œìž…ë‹ˆë‹¤.

## ðŸŽ¯ ì£¼ìš” ê¸°ëŠ¥

- ë„¤ì´ë²„ ë‰´ìŠ¤ APIë¥¼ í†µí•œ ìžë™ ë‰´ìŠ¤ ìˆ˜ì§‘
- HTML íƒœê·¸ ë° ì—”í‹°í‹° ìžë™ ì²˜ë¦¬
- ê¸°ì‚¬ ì¤‘ë³µ ê²€ì‚¬ ë° í•„í„°ë§
- Supabase ë°ì´í„°ë² ì´ìŠ¤ ìžë™ ì €ìž¥
- ë°ì´í„° ê²€ì¦ ë° ì—ëŸ¬ í•¸ë“¤ë§

## ðŸ“‹ ë°ì´í„° ê²€ì¦ ê·œì¹™

ìˆ˜ì •ëœ ê²€ì¦ ê·œì¹™:
- **ì œëª©**: ìµœì†Œ 9ìž ì´ìƒ
- **ë³¸ë¬¸**: ìµœëŒ€ 700ìžê¹Œì§€ ì €ìž¥
- **URL**: ë„¤ì´ë²„ ë‰´ìŠ¤ URLë§Œ í—ˆìš©
- **ë‚šì‹œ ì ìˆ˜**: 0-100 ë²”ìœ„ ë‚´ ì •ìˆ˜ê°’

## ðŸ› ï¸ ê¸°ìˆ  ìŠ¤íƒ

- **Python 3.9+** - ë©”ì¸ ê°œë°œ ì–¸ì–´
- **Supabase** - ë©”ì¸ ë°ì´í„°ë² ì´ìŠ¤ (PostgreSQL)
- **Naver Open API** - ë‰´ìŠ¤ ê²€ìƒ‰ API
- **Requests/BeautifulSoup** - ì›¹ í¬ë¡¤ë§
- **Pytest** - í…ŒìŠ¤íŠ¸ í”„ë ˆìž„ì›Œí¬

## ðŸ“¦ ì„¤ì¹˜ ë° ì„¤ì •

### 1. ì˜ì¡´ì„± ì„¤ì¹˜

```bash
pip install -r requirements.txt
```

### 2. í™˜ê²½ ë³€ìˆ˜ ì„¤ì •

`.env` íŒŒì¼ì„ ìƒì„±í•˜ê³  ë‹¤ìŒ ë‚´ìš©ì„ ìž…ë ¥:

```env
# Supabase Configuration
SUPABASE_URL=your-supabase-url
SUPABASE_KEY=your-supabase-service-role-key

# Naver API Configuration
NAVER_CLIENT_ID=your-naver-client-id
NAVER_CLIENT_SECRET=your-naver-client-secret
```

### 3. ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤í‚¤ë§ˆ ì„¤ì •

Supabaseì—ì„œ ë‹¤ìŒ í…Œì´ë¸”ì„ ìƒì„±:

```sql
-- ê¸°ìž í…Œì´ë¸”
CREATE TABLE journalists (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  name TEXT NOT NULL,
  naver_uuid TEXT,
  publisher TEXT NOT NULL,
  article_count INTEGER DEFAULT 0,
  average_score DECIMAL(5,2) DEFAULT 0.00,
  max_score INTEGER DEFAULT 0,
  created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
  updated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()
);

-- ê¸°ì‚¬ í…Œì´ë¸”
CREATE TABLE articles (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  title TEXT NOT NULL,
  content TEXT NOT NULL,
  journalist_id UUID NOT NULL REFERENCES journalists(id),
  publisher TEXT NOT NULL,
  clickbait_score INTEGER CHECK (clickbait_score >= 0 AND clickbait_score <= 100),
  score_explanation TEXT,
  published_at TIMESTAMP WITH TIME ZONE NOT NULL,
  naver_url TEXT UNIQUE,
  created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
  updated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()
);
```

## ðŸš€ ì‚¬ìš©ë²•

### ê¸°ë³¸ ì‹¤í–‰

```bash
python main.py
```

### ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰

```bash
# ê¸°ë³¸ í‚¤ì›Œë“œë¡œ í¬ë¡¤ë§
python scripts/crawl_news.py

# íŠ¹ì • í‚¤ì›Œë“œë¡œ í¬ë¡¤ë§
python scripts/crawl_news.py --keywords ì¶©ê²© ê³µí¬ ë°˜ì „

# í‚¤ì›Œë“œë‹¹ ìµœëŒ€ ê¸°ì‚¬ ìˆ˜ ì„¤ì •
python scripts/crawl_news.py --max-per-keyword 30

# í…ŒìŠ¤íŠ¸ ëª¨ë“œ (ì‹¤ì œ ì €ìž¥ ì•ˆí•¨)
python scripts/crawl_news.py --dry-run
```

## ðŸ§ª í…ŒìŠ¤íŠ¸

### ì „ì²´ í…ŒìŠ¤íŠ¸ ì‹¤í–‰

```bash
python -m pytest tests/ -v
```

### ê°œë³„ í…ŒìŠ¤íŠ¸ ì‹¤í–‰

```bash
# ëª¨ë¸ í…ŒìŠ¤íŠ¸
python -m pytest tests/test_models.py -v

# ë°ì´í„°ë² ì´ìŠ¤ í…ŒìŠ¤íŠ¸
python -m pytest tests/test_database.py -v

# í¬ë¡¤ëŸ¬ í…ŒìŠ¤íŠ¸
python -m pytest tests/test_crawler.py -v
```

## ðŸ“ í”„ë¡œì íŠ¸ êµ¬ì¡°

```
clickmaster-crawler/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ models/          # ë°ì´í„° ëª¨ë¸
â”‚   â”‚   â””â”€â”€ article.py   # Article, Journalist ëª¨ë¸
â”‚   â”œâ”€â”€ database/        # ë°ì´í„°ë² ì´ìŠ¤ ì—°ì‚°
â”‚   â”‚   â”œâ”€â”€ supabase_client.py
â”‚   â”‚   â””â”€â”€ operations.py
â”‚   â”œâ”€â”€ crawlers/        # í¬ë¡¤ë§ ë¡œì§
â”‚   â”‚   â””â”€â”€ naver_crawler.py
â”‚   â””â”€â”€ config/          # ì„¤ì • íŒŒì¼
â”‚       â””â”€â”€ settings.py
â”œâ”€â”€ scripts/             # ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸
â”‚   â””â”€â”€ crawl_news.py
â”œâ”€â”€ tests/               # í…ŒìŠ¤íŠ¸ ì½”ë“œ
â”‚   â”œâ”€â”€ test_models.py
â”‚   â”œâ”€â”€ test_database.py
â”‚   â””â”€â”€ test_crawler.py
â”œâ”€â”€ logs/                # ë¡œê·¸ íŒŒì¼
â”œâ”€â”€ main.py              # ë©”ì¸ ì‹¤í–‰ íŒŒì¼
â””â”€â”€ requirements.txt     # ì˜ì¡´ì„± ëª©ë¡
```

## ðŸ” ë°ì´í„° í”Œë¡œìš°

1. **ë‰´ìŠ¤ ìˆ˜ì§‘**: ë„¤ì´ë²„ ë‰´ìŠ¤ APIë¥¼ í†µí•´ í‚¤ì›Œë“œë³„ ë‰´ìŠ¤ ê²€ìƒ‰
2. **ë°ì´í„° ì²˜ë¦¬**: HTML íƒœê·¸/ì—”í‹°í‹° ì œê±°, ë‚´ìš© ê¸¸ì´ ê²€ì¦
3. **ì¤‘ë³µ ì œê±°**: ë„¤ì´ë²„ URL ê¸°ì¤€ ì¤‘ë³µ ê¸°ì‚¬ í•„í„°ë§
4. **ê¸°ìž ê´€ë¦¬**: ê¸°ìž ì •ë³´ ìžë™ ìƒì„±/ì¡°íšŒ
5. **ë°ì´í„° ì €ìž¥**: Supabase ë°ì´í„°ë² ì´ìŠ¤ì— ì•ˆì „í•˜ê²Œ ì €ìž¥

## ðŸŽ¨ ê°œë°œ ì›ì¹™

- **TDD (Test-Driven Development)**: í…ŒìŠ¤íŠ¸ ìš°ì„  ê°œë°œ
- **SOLID ì›ì¹™**: ê°ì²´ì§€í–¥ ì„¤ê³„ ì›ì¹™ ì¤€ìˆ˜
- **Clean Architecture**: ê³„ì¸µ ë¶„ë¦¬ ë° ì˜ì¡´ì„± ê´€ë¦¬
- **ëª¨ë“ˆí™”**: ê¸°ëŠ¥ë³„ ë…ë¦½ì ì¸ ëª¨ë“ˆ ì„¤ê³„

## ðŸ“Š ë¡œê¹…

ëª¨ë“  ì¤‘ìš”í•œ ìž‘ì—…ì€ ë¡œê·¸ë¡œ ê¸°ë¡ë©ë‹ˆë‹¤:

```
logs/
â”œâ”€â”€ main_20240115.log           # ë©”ì¸ ì‹¤í–‰ ë¡œê·¸
â”œâ”€â”€ crawl_news_20240115.log     # í¬ë¡¤ë§ ë¡œê·¸
â””â”€â”€ ...
```

## ðŸ”§ ì„¤ì • ì˜µì…˜

`src/config/settings.py`ì—ì„œ ë‹¤ìŒ ì˜µì…˜ì„ ì¡°ì •í•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤:

- `DEFAULT_KEYWORDS`: ê¸°ë³¸ ê²€ìƒ‰ í‚¤ì›Œë“œ
- `MAX_ARTICLES_PER_KEYWORD`: í‚¤ì›Œë“œë‹¹ ìµœëŒ€ ê¸°ì‚¬ ìˆ˜
- `CRAWL_DELAY_SECONDS`: í¬ë¡¤ë§ ê°„ê²©
- `LOG_LEVEL`: ë¡œê·¸ ë ˆë²¨

## ðŸš¨ ì£¼ì˜ì‚¬í•­

- ë„¤ì´ë²„ API ì‚¬ìš©ëŸ‰ ì œí•œì„ ì¤€ìˆ˜í•˜ì„¸ìš”
- í¬ë¡¤ë§ ê°„ê²©ì„ ì ì ˆížˆ ì„¤ì •í•˜ì—¬ ì„œë²„ ë¶€í•˜ë¥¼ ë°©ì§€í•˜ì„¸ìš”
- í™˜ê²½ ë³€ìˆ˜ë¥¼ ì•ˆì „í•˜ê²Œ ê´€ë¦¬í•˜ì„¸ìš”
- ì •ê¸°ì ìœ¼ë¡œ ë¡œê·¸ë¥¼ í™•ì¸í•˜ê³  ì •ë¦¬í•˜ì„¸ìš”

## ðŸ¤ ê¸°ì—¬í•˜ê¸°

1. Fork the repository
2. Create a feature branch
3. Write tests for new features
4. Ensure all tests pass
5. Submit a pull request

## ðŸ“„ ë¼ì´ì„ ìŠ¤

MIT License 