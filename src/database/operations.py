"""
Supabase ë°ì´í„°ë² ì´ìŠ¤ ì—°ì‚°
"""

from typing import List, Optional, Dict, Any
from datetime import datetime
import logging

from src.models.article import Article, Journalist
from src.database.supabase_client import get_supabase_client

logger = logging.getLogger(__name__)


class DatabaseOperations:
    """ë°ì´í„°ë² ì´ìŠ¤ ì—°ì‚° í´ë˜ìŠ¤"""

    def __init__(self):
        self.client = get_supabase_client()

    def get_or_create_journalist(self, name: str, publisher: str, naver_uuid: Optional[str] = None) -> Dict[str, Any]:
        """
        ê¸°ì ì •ë³´ ì¡°íšŒ ë˜ëŠ” ìƒì„±

        Args:
            name: ê¸°ìëª…
            publisher: ì–¸ë¡ ì‚¬
            naver_uuid: ë„¤ì´ë²„ UUID (ì„ íƒ)

        Returns:
            ê¸°ì ì •ë³´ ë”•ì…”ë„ˆë¦¬
        """
        try:
            # ì´ë¦„ê³¼ ì–¸ë¡ ì‚¬ ì •ê·œí™”
            name = name.strip()
            publisher = publisher.strip()

            # ìµëª… ê¸°ì ì²˜ë¦¬ - ê° ì–¸ë¡ ì‚¬ë³„ë¡œ ë³„ë„ì˜ ìµëª… ê¸°ì ìƒì„±
            if name in ["ìµëª…", "ê¸°ì", "", " "]:
                name = f"ìµëª…ê¸°ì_{publisher}"
                logger.debug(f"ìµëª… ê¸°ìëª… ì •ê·œí™”: {name}")

            # ê¸°ì¡´ ê¸°ì ì¡°íšŒ
            existing = (
                self.client.client.table("journalists")
                .select("*")
                .eq("name", name)
                .eq("publisher", publisher)
                .execute()
            )

            if existing.data:
                journalist_info = existing.data[0]
                logger.debug(f"ê¸°ì¡´ ê¸°ì ì¡°íšŒ: {name} ({publisher}) - ID: {journalist_info['id']}")
                return journalist_info

            # ìƒˆ ê¸°ì ìƒì„±
            journalist = Journalist(name=name, publisher=publisher, naver_uuid=naver_uuid)
            journalist_data = journalist.to_dict()

            result = self.client.client.table("journalists").insert(journalist_data).execute()

            if result.data:
                new_journalist = result.data[0]
                logger.info(f"ğŸ†• ìƒˆ ê¸°ì ìƒì„±: {name} ({publisher}) - ID: {new_journalist['id']}")
                return new_journalist
            else:
                raise Exception("ê¸°ì ìƒì„± ì‹¤íŒ¨ - ì‘ë‹µ ë°ì´í„° ì—†ìŒ")

        except Exception as e:
            logger.error(f"ê¸°ì ì¡°íšŒ/ìƒì„± ì˜¤ë¥˜ [{name}, {publisher}]: {e}")
            raise

    def get_or_create_journalists_batch(self, journalist_specs: List[tuple]) -> Dict[str, Dict[str, Any]]:
        """
        ê¸°ìë“¤ì„ ë°°ì¹˜ë¡œ ì¡°íšŒ/ìƒì„± (ì„±ëŠ¥ ìµœì í™”)

        Args:
            journalist_specs: (name, publisher) íŠœí”Œ ë¦¬ìŠ¤íŠ¸

        Returns:
            í‚¤ê°€ "name_publisher" í˜•íƒœì¸ ê¸°ì ì •ë³´ ë”•ì…”ë„ˆë¦¬
        """
        try:
            if not journalist_specs:
                return {}

            # 1ë‹¨ê³„: ê¸°ìëª… ì •ê·œí™” ë° ìœ ë‹ˆí¬í•œ ê¸°ìë“¤ ìˆ˜ì§‘
            normalized_specs = []
            unique_keys = set()

            for name, publisher in journalist_specs:
                # ì •ê·œí™”
                name = name.strip()
                publisher = publisher.strip()

                # ìµëª… ê¸°ì ì²˜ë¦¬
                if name in ["ìµëª…", "ê¸°ì", "", " "]:
                    name = f"ìµëª…ê¸°ì_{publisher}"

                journalist_key = f"{name}_{publisher}"
                if journalist_key not in unique_keys:
                    normalized_specs.append((name, publisher))
                    unique_keys.add(journalist_key)

            if not normalized_specs:
                return {}

            logger.info(f"ë°°ì¹˜ ê¸°ì ì²˜ë¦¬ ì‹œì‘: {len(normalized_specs)}ëª…")

            # 2ë‹¨ê³„: ê¸°ì¡´ ê¸°ìë“¤ ì¼ê´„ ì¡°íšŒ (ì§„ì§œ ë°°ì¹˜ ì²˜ë¦¬)
            existing_journalists = {}
            if normalized_specs:
                # ëª¨ë“  ì´ë¦„ê³¼ ì¶œíŒì‚¬ë¥¼ ìˆ˜ì§‘
                all_names = list(set([name for name, publisher in normalized_specs]))
                all_publishers = list(set([publisher for name, publisher in normalized_specs]))

                logger.info(f"ë°°ì¹˜ ê¸°ì ì¡°íšŒ: {len(all_names)}ê°œ ì´ë¦„, {len(all_publishers)}ê°œ ì¶œíŒì‚¬")

                try:
                    # í•œ ë²ˆì˜ ì¿¼ë¦¬ë¡œ ëª¨ë“  ê´€ë ¨ ê¸°ìë“¤ ì¡°íšŒ
                    result = (
                        self.client.client.table("journalists")
                        .select("*")
                        .in_("name", all_names)
                        .in_("publisher", all_publishers)
                        .execute()
                    )

                    # í´ë¼ì´ì–¸íŠ¸ì—ì„œ ì •í™•í•œ (name, publisher) ì¡°í•© í•„í„°ë§
                    target_combinations = set(normalized_specs)
                    for journalist in result.data:
                        journalist_combo = (journalist["name"], journalist["publisher"])
                        if journalist_combo in target_combinations:
                            key = f"{journalist['name']}_{journalist['publisher']}"
                            existing_journalists[key] = journalist

                    logger.info(f"ê¸°ì¡´ ê¸°ì ì¡°íšŒ ì™„ë£Œ: {len(existing_journalists)}ëª… (ë‹¨ì¼ ì¿¼ë¦¬)")

                except Exception as e:
                    logger.error(f"ë°°ì¹˜ ê¸°ì ì¡°íšŒ ì‹¤íŒ¨: {e}")
                    # ì‹¤íŒ¨ ì‹œ ê°œë³„ ì¡°íšŒë¡œ í´ë°±
                    logger.warning("ê°œë³„ ê¸°ì ì¡°íšŒë¡œ í´ë°±í•©ë‹ˆë‹¤...")
                    for name, publisher in normalized_specs:
                        try:
                            result = (
                                self.client.client.table("journalists")
                                .select("*")
                                .eq("name", name)
                                .eq("publisher", publisher)
                                .execute()
                            )

                            for journalist in result.data:
                                key = f"{journalist['name']}_{journalist['publisher']}"
                                existing_journalists[key] = journalist

                        except Exception as individual_e:
                            logger.warning(f"ê°œë³„ ê¸°ì ì¡°íšŒ ì‹¤íŒ¨ [{name}, {publisher}]: {individual_e}")
                            continue

            # 3ë‹¨ê³„: ìƒˆë¡œ ìƒì„±í•  ê¸°ìë“¤ ì‹ë³„
            new_journalists_data = []
            for name, publisher in normalized_specs:
                journalist_key = f"{name}_{publisher}"
                if journalist_key not in existing_journalists:
                    journalist = Journalist(name=name, publisher=publisher)
                    new_journalists_data.append(journalist.to_dict())

            # 4ë‹¨ê³„: ìƒˆ ê¸°ìë“¤ ë°°ì¹˜ ìƒì„±
            if new_journalists_data:
                logger.info(f"ìƒˆ ê¸°ì ë°°ì¹˜ ìƒì„±: {len(new_journalists_data)}ëª…")
                try:
                    result = self.client.client.table("journalists").insert(new_journalists_data).execute()

                    if result.data:
                        # ìƒˆë¡œ ìƒì„±ëœ ê¸°ìë“¤ì„ ê¸°ì¡´ ê¸°ì ë”•ì…”ë„ˆë¦¬ì— ì¶”ê°€
                        for journalist in result.data:
                            key = f"{journalist['name']}_{journalist['publisher']}"
                            existing_journalists[key] = journalist
                            logger.debug(
                                f"ğŸ†• ìƒˆ ê¸°ì ìƒì„±: {journalist['name']} ({journalist['publisher']}) - ID: {journalist['id']}"
                            )
                    else:
                        logger.error("ë°°ì¹˜ ê¸°ì ìƒì„± ì‹¤íŒ¨ - ì‘ë‹µ ë°ì´í„° ì—†ìŒ")

                except Exception as e:
                    logger.error(f"ë°°ì¹˜ ê¸°ì ìƒì„± ì‹¤íŒ¨: {e}")
                    # ì‹¤íŒ¨ ì‹œ ê°œë³„ ìƒì„±ìœ¼ë¡œ í´ë°±
                    for journalist_data in new_journalists_data:
                        try:
                            individual_result = (
                                self.client.client.table("journalists").insert(journalist_data).execute()
                            )
                            if individual_result.data:
                                journalist = individual_result.data[0]
                                key = f"{journalist['name']}_{journalist['publisher']}"
                                existing_journalists[key] = journalist
                                logger.info(f"ğŸ†• ê°œë³„ ê¸°ì ìƒì„±: {journalist['name']} ({journalist['publisher']})")
                        except Exception as individual_e:
                            logger.error(
                                f"ê°œë³„ ê¸°ì ìƒì„± ì‹¤íŒ¨ [{journalist_data['name']}, {journalist_data['publisher']}]: {individual_e}"
                            )
                            continue

            logger.info(f"ë°°ì¹˜ ê¸°ì ì²˜ë¦¬ ì™„ë£Œ: ì´ {len(existing_journalists)}ëª…")
            return existing_journalists

        except Exception as e:
            logger.error(f"ë°°ì¹˜ ê¸°ì ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
            return {}

    def insert_article(self, article: Article) -> Dict[str, Any]:
        """
        ê¸°ì‚¬ ì‚½ì…

        Args:
            article: ê¸°ì‚¬ ê°ì²´

        Returns:
            ì‚½ì…ëœ ê¸°ì‚¬ ì •ë³´
        """
        try:
            # ê¸°ì ì •ë³´ ì¡°íšŒ/ìƒì„±
            journalist = self.get_or_create_journalist(article.journalist_name, article.publisher)

            # ê¸°ì‚¬ ë°ì´í„° ì¤€ë¹„
            article.journalist_id = journalist["id"]
            article_data = article.to_dict()

            # ê¸°ì‚¬ ì‚½ì…
            result = self.client.client.table("articles").insert(article_data).execute()

            if result.data:
                logger.info(f"ê¸°ì‚¬ ì‚½ì… ì™„ë£Œ: {article.title[:50]}...")
                return result.data[0]
            else:
                raise Exception("ê¸°ì‚¬ ì‚½ì… ì‹¤íŒ¨")

        except Exception as e:
            logger.error(f"ê¸°ì‚¬ ì‚½ì… ì˜¤ë¥˜: {e}")
            raise

    def bulk_insert_articles(self, articles: List[Article]) -> List[Dict[str, Any]]:
        """
        ê¸°ì‚¬ ë°°ì¹˜ ì‚½ì… (Supabase ë°°ì¹˜ ì‚½ì… í™œìš©)

        Args:
            articles: ê¸°ì‚¬ ë¦¬ìŠ¤íŠ¸

        Returns:
            ì‚½ì…ëœ ê¸°ì‚¬ ì •ë³´ ë¦¬ìŠ¤íŠ¸
        """
        if not articles:
            logger.warning("ì‚½ì…í•  ê¸°ì‚¬ê°€ ì—†ìŠµë‹ˆë‹¤")
            return []

        logger.info(f"ë°°ì¹˜ ì‚½ì… ì‹œì‘: {len(articles)}ê°œ ê¸°ì‚¬")

        try:
            # 1ë‹¨ê³„: ëª¨ë“  ê¸°ì ì •ë³´ë¥¼ ë°°ì¹˜ë¡œ ì²˜ë¦¬
            unique_journalists = []
            seen_journalists = set()

            # ê¸°ì‚¬ ìˆœì„œëŒ€ë¡œ ê³ ìœ í•œ ê¸°ìë“¤ì„ ìˆ˜ì§‘ (ìˆœì„œ ë³´ì¥)
            for article in articles:
                journalist_tuple = (article.journalist_name, article.publisher)
                if journalist_tuple not in seen_journalists:
                    unique_journalists.append(journalist_tuple)
                    seen_journalists.add(journalist_tuple)

            logger.info(f"ì²˜ë¦¬í•  ê³ ìœ  ê¸°ì ìˆ˜: {len(unique_journalists)}")

            # ë°°ì¹˜ë¡œ ê¸°ì ì¡°íšŒ/ìƒì„±
            journalist_cache = self.get_or_create_journalists_batch(unique_journalists)

            # 2ë‹¨ê³„: ê¸°ì‚¬ ë°ì´í„° ì¤€ë¹„ (ë°°ì¹˜ ì‚½ì…ìš©)
            articles_data = []
            skipped_count = 0

            for article in articles:
                journalist_key = f"{article.journalist_name}_{article.publisher}"

                if journalist_key not in journalist_cache:
                    logger.warning(f"ê¸°ì ì •ë³´ê°€ ì—†ì–´ ê¸°ì‚¬ ì œì™¸: {article.title[:50]}...")
                    skipped_count += 1
                    continue

                # ê¸°ì‚¬ì— ê¸°ì ID ì„¤ì •
                article.journalist_id = journalist_cache[journalist_key]["id"]
                article_data = article.to_dict()
                articles_data.append(article_data)

            if not articles_data:
                logger.warning("ì‚½ì…í•  ìˆ˜ ìˆëŠ” ê¸°ì‚¬ê°€ ì—†ìŠµë‹ˆë‹¤")
                return []

            logger.info(f"ë°°ì¹˜ ì‚½ì… ì¤€ë¹„ ì™„ë£Œ: {len(articles_data)}ê°œ ê¸°ì‚¬ (ì œì™¸: {skipped_count}ê°œ)")

            # 3ë‹¨ê³„: Supabase ë°°ì¹˜ ì‚½ì… ì‹¤í–‰
            result = self.client.client.table("articles").insert(articles_data).execute()

            if result.data:
                inserted_count = len(result.data)
                logger.info(f"ë°°ì¹˜ ì‚½ì… ì™„ë£Œ: {inserted_count}ê°œ ê¸°ì‚¬ ì„±ê³µ")

                # ì²˜ë¦¬ëœ ê¸°ì ì •ë³´ ë¡œê¹…
                logger.info(f"ì²˜ë¦¬ëœ ê¸°ì ìˆ˜: {len(journalist_cache)}ëª…")
                for journalist_key, journalist_info in journalist_cache.items():
                    name, publisher = journalist_key.split("_", 1)
                    logger.info(f"  - {name} ({publisher}): ID {journalist_info['id']}")

                return result.data
            else:
                logger.error("ë°°ì¹˜ ì‚½ì… ì‹¤íŒ¨ - ì‘ë‹µ ë°ì´í„° ì—†ìŒ")
                return []

        except Exception as e:
            error_msg = str(e)
            logger.error(f"ë°°ì¹˜ ì‚½ì… ì‹¤í–‰ ì˜¤ë¥˜: {e}")

            # unique constraint ìœ„ë°˜ ì˜¤ë¥˜ì¸ì§€ í™•ì¸
            if "23505" in error_msg or "duplicate key value" in error_msg:
                logger.warning("ë°°ì¹˜ ì‚½ì… ì¤‘ ì¤‘ë³µ í‚¤ ì˜¤ë¥˜ ë°œìƒ - ê°œë³„ ì‚½ì…ìœ¼ë¡œ ì¤‘ë³µ í•­ëª© ìŠ¤í‚µ")

            # ì˜¤ë¥˜ ë°œìƒ ì‹œ ê°œë³„ ì‚½ì…ìœ¼ë¡œ í´ë°±
            logger.info("ê°œë³„ ì‚½ì…ìœ¼ë¡œ í´ë°± ì‹œì‘...")
            return self._fallback_individual_insert(articles, journalist_cache)

    def _fallback_individual_insert(
        self, articles: List[Article], journalist_cache: Dict[str, Dict[str, Any]]
    ) -> List[Dict[str, Any]]:
        """
        ë°°ì¹˜ ì‚½ì… ì‹¤íŒ¨ ì‹œ ê°œë³„ ì‚½ì…ìœ¼ë¡œ í´ë°±

        Args:
            articles: ê¸°ì‚¬ ë¦¬ìŠ¤íŠ¸
            journalist_cache: ì´ë¯¸ ì²˜ë¦¬ëœ ê¸°ì ìºì‹œ

        Returns:
            ì‚½ì…ëœ ê¸°ì‚¬ ì •ë³´ ë¦¬ìŠ¤íŠ¸
        """
        inserted_articles = []

        logger.warning("ê°œë³„ ì‚½ì… ëª¨ë“œë¡œ ì§„í–‰í•©ë‹ˆë‹¤...")
        logger.info(f"ê¸°ì ìºì‹œ ì¬ì‚¬ìš©: {len(journalist_cache)}ëª…")

        for i, article in enumerate(articles, 1):
            try:
                # ê¸°ì ìºì‹œ í‚¤ ìƒì„± (ì´ë¦„ + ì–¸ë¡ ì‚¬)
                journalist_key = f"{article.journalist_name}_{article.publisher}"

                # ìºì‹œì—ì„œ ê¸°ì ì •ë³´ ì¡°íšŒ (ì´ë¯¸ ë°°ì¹˜ë¡œ ì²˜ë¦¬ëœ ìºì‹œ ì‚¬ìš©)
                if journalist_key not in journalist_cache:
                    # ì˜ˆìƒì¹˜ ëª»í•œ ê²½ìš°ì—ë§Œ ê°œë³„ ì¡°íšŒ (ì´ë¡ ì ìœ¼ë¡œ ë°œìƒí•˜ì§€ ì•Šì•„ì•¼ í•¨)
                    logger.warning(
                        f"ìºì‹œì— ì—†ëŠ” ê¸°ì ë°œê²¬ - ê°œë³„ ì¡°íšŒ: {article.journalist_name} ({article.publisher})"
                    )
                    journalist = self.get_or_create_journalist(article.journalist_name, article.publisher)
                    journalist_cache[journalist_key] = journalist
                else:
                    journalist = journalist_cache[journalist_key]

                # ê¸°ì‚¬ì— ê¸°ì ID ì„¤ì •
                article.journalist_id = journalist["id"]
                article_data = article.to_dict()

                # ê¸°ì‚¬ ì‚½ì…
                result = self.client.client.table("articles").insert(article_data).execute()

                if result.data:
                    inserted_articles.append(result.data[0])
                    logger.debug(f"ê¸°ì‚¬ ì‚½ì… ì™„ë£Œ ({i}/{len(articles)}): {article.title[:50]}...")
                else:
                    error_msg = str(result.error) if result.error else "ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜"
                    logger.warning(f"ê¸°ì‚¬ ì‚½ì… ì‹¤íŒ¨ ({i}/{len(articles)}): {article.title[:50]}... - {error_msg}")

            except Exception as e:
                logger.error(f"ê¸°ì‚¬ ì‚½ì… ì‹¤íŒ¨ ({i}/{len(articles)}): {article.title[:50]}... - {e}")
                continue

        logger.info(f"ê°œë³„ ì‚½ì… ì™„ë£Œ: {len(inserted_articles)}/{len(articles)}ê°œ ê¸°ì‚¬")
        return inserted_articles

    def check_duplicate_article(self, naver_url: str) -> bool:
        """
        ì¤‘ë³µ ê¸°ì‚¬ ì²´í¬

        Args:
            naver_url: ë„¤ì´ë²„ ë‰´ìŠ¤ URL

        Returns:
            ì¤‘ë³µ ì—¬ë¶€
        """
        try:
            result = self.client.client.table("articles").select("id").eq("naver_url", naver_url).execute()

            return len(result.data) > 0

        except Exception as e:
            logger.error(f"ì¤‘ë³µ ì²´í¬ ì˜¤ë¥˜: {e}")
            return False

    def check_duplicate_articles_batch(self, naver_urls: List[str]) -> Dict[str, bool]:
        """
        ë°°ì¹˜ë¡œ ì¤‘ë³µ ê¸°ì‚¬ ì²´í¬ (ì„±ëŠ¥ ìµœì í™”)

        Args:
            naver_urls: ë„¤ì´ë²„ ë‰´ìŠ¤ URL ë¦¬ìŠ¤íŠ¸

        Returns:
            URLë³„ ì¤‘ë³µ ì—¬ë¶€ ë”•ì…”ë„ˆë¦¬
        """
        try:
            if not naver_urls:
                return {}

            # ê¸°ì¡´ URLë“¤ ì¡°íšŒ (í•œ ë²ˆì˜ ì¿¼ë¦¬ë¡œ ì²˜ë¦¬)
            result = self.client.client.table("articles").select("naver_url").in_("naver_url", naver_urls).execute()

            existing_urls = {item["naver_url"] for item in result.data}

            # ëª¨ë“  URLì— ëŒ€í•œ ì¤‘ë³µ ì—¬ë¶€ ë°˜í™˜
            return {url: url in existing_urls for url in naver_urls}

        except Exception as e:
            logger.error(f"ë°°ì¹˜ ì¤‘ë³µ ì²´í¬ ì˜¤ë¥˜: {e}")
            # ì‹¤íŒ¨ ì‹œ ëª¨ë“  URLì„ ì¤‘ë³µ ì—†ìŒìœ¼ë¡œ ì²˜ë¦¬
            return {url: False for url in naver_urls}

    def get_unprocessed_articles(self, limit: int = 1000) -> List[Dict[str, Any]]:
        """
        ë¯¸ì²˜ë¦¬ ê¸°ì‚¬ ì¡°íšŒ (clickbait_scoreê°€ nullì¸ ê¸°ì‚¬)

        Args:
            limit: ì¡°íšŒ ì œí•œ ìˆ˜

        Returns:
            ë¯¸ì²˜ë¦¬ ê¸°ì‚¬ ë¦¬ìŠ¤íŠ¸
        """
        try:
            result = (
                self.client.client.table("articles").select("*").is_("clickbait_score", "null").limit(limit).execute()
            )

            logger.info(f"ë¯¸ì²˜ë¦¬ ê¸°ì‚¬ ì¡°íšŒ: {len(result.data)}ê°œ")
            return result.data

        except Exception as e:
            logger.error(f"ë¯¸ì²˜ë¦¬ ê¸°ì‚¬ ì¡°íšŒ ì˜¤ë¥˜: {e}")
            return []

    def update_article_score(self, article_id: str, clickbait_score: int, clickbait_explanation: str) -> bool:
        """
        ê¸°ì‚¬ ë‚šì‹œ ì ìˆ˜ ì—…ë°ì´íŠ¸

        Args:
            article_id: ê¸°ì‚¬ ID
            clickbait_score: ë‚šì‹œ ì ìˆ˜ (0-100)
            clickbait_explanation: ì ìˆ˜ ì„¤ëª…

        Returns:
            ì—…ë°ì´íŠ¸ ì„±ê³µ ì—¬ë¶€
        """
        try:
            result = (
                self.client.client.table("articles")
                .update(
                    {
                        "clickbait_score": clickbait_score,
                        "clickbait_explanation": clickbait_explanation,
                        "updated_at": datetime.now().isoformat(),
                    }
                )
                .eq("id", article_id)
                .execute()
            )

            success = len(result.data) > 0
            if success:
                logger.info(f"ê¸°ì‚¬ ì ìˆ˜ ì—…ë°ì´íŠ¸ ì™„ë£Œ: {article_id}")

            return success

        except Exception as e:
            logger.error(f"ê¸°ì‚¬ ì ìˆ˜ ì—…ë°ì´íŠ¸ ì˜¤ë¥˜: {e}")
            return False

    def update_journalist_stats_manual(self, journalist_id: str) -> bool:
        """
        íŠ¹ì • ê¸°ìì˜ í†µê³„ ìˆ˜ë™ ì—…ë°ì´íŠ¸

        Args:
            journalist_id: ê¸°ì ID

        Returns:
            ì—…ë°ì´íŠ¸ ì„±ê³µ ì—¬ë¶€
        """
        try:
            # í•´ë‹¹ ê¸°ìì˜ ëª¨ë“  ê¸°ì‚¬ í†µê³„ ê³„ì‚°
            result = (
                self.client.client.table("articles")
                .select("clickbait_score")
                .eq("journalist_id", journalist_id)
                .execute()
            )

            if not result.data:
                logger.warning(f"ê¸°ì ID {journalist_id}ì˜ ê¸°ì‚¬ê°€ ì—†ìŠµë‹ˆë‹¤")
                return False

            # í†µê³„ ê³„ì‚°
            total_articles = len(result.data)
            scored_articles = [article for article in result.data if article["clickbait_score"] is not None]

            if scored_articles:
                scores = [article["clickbait_score"] for article in scored_articles]
                avg_score = sum(scores) / len(scores)
                max_score = max(scores)
            else:
                avg_score = 0.0
                max_score = 0

            # ê¸°ì í†µê³„ ì—…ë°ì´íŠ¸
            update_result = (
                self.client.client.table("journalists")
                .update(
                    {
                        "article_count": total_articles,
                        "avg_clickbait_score": round(avg_score, 2),
                        "max_score": max_score,
                        "updated_at": datetime.now().isoformat(),
                    }
                )
                .eq("id", journalist_id)
                .execute()
            )

            success = len(update_result.data) > 0
            if success:
                logger.info(
                    f"ê¸°ì í†µê³„ ì—…ë°ì´íŠ¸ ì™„ë£Œ: {journalist_id} (ê¸°ì‚¬ìˆ˜: {total_articles}, í‰ê· : {avg_score:.2f}, ìµœê³ : {max_score})"
                )

            return success

        except Exception as e:
            logger.error(f"ê¸°ì í†µê³„ ì—…ë°ì´íŠ¸ ì˜¤ë¥˜: {e}")
            return False

    def update_all_journalist_stats(self) -> Dict[str, Any]:
        """
        ëª¨ë“  ê¸°ìì˜ í†µê³„ ì¼ê´„ ì—…ë°ì´íŠ¸

        Returns:
            ì—…ë°ì´íŠ¸ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        """
        try:
            # ëª¨ë“  ê¸°ì ì¡°íšŒ
            journalists_result = self.client.client.table("journalists").select("id, name, publisher").execute()

            if not journalists_result.data:
                logger.warning("ì—…ë°ì´íŠ¸í•  ê¸°ìê°€ ì—†ìŠµë‹ˆë‹¤")
                return {"success": 0, "failed": 0, "total": 0}

            success_count = 0
            failed_count = 0
            total_count = len(journalists_result.data)

            logger.info(f"ì´ {total_count}ëª…ì˜ ê¸°ì í†µê³„ ì—…ë°ì´íŠ¸ ì‹œì‘")

            for journalist in journalists_result.data:
                try:
                    if self.update_journalist_stats_manual(journalist["id"]):
                        success_count += 1
                    else:
                        failed_count += 1
                        logger.error(f"ê¸°ì í†µê³„ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {journalist['name']} ({journalist['publisher']})")
                except Exception as e:
                    failed_count += 1
                    logger.error(f"ê¸°ì í†µê³„ ì—…ë°ì´íŠ¸ ì˜ˆì™¸: {journalist['name']} ({journalist['publisher']}) - {e}")

            result = {"success": success_count, "failed": failed_count, "total": total_count}

            logger.info(f"ê¸°ì í†µê³„ ì¼ê´„ ì—…ë°ì´íŠ¸ ì™„ë£Œ: ì„±ê³µ {success_count}/{total_count}, ì‹¤íŒ¨ {failed_count}")
            return result

        except Exception as e:
            logger.error(f"ê¸°ì í†µê³„ ì¼ê´„ ì—…ë°ì´íŠ¸ ì˜¤ë¥˜: {e}")
            return {"success": 0, "failed": 0, "total": 0, "error": str(e)}

    def get_journalist_stats_summary(self) -> Dict[str, Any]:
        """
        ê¸°ì í†µê³„ ìš”ì•½ ì •ë³´ ì¡°íšŒ

        Returns:
            í†µê³„ ìš”ì•½ ë”•ì…”ë„ˆë¦¬
        """
        try:
            # ê¸°ì ì´ ìˆ˜
            journalists_result = self.client.client.table("journalists").select("id", count="exact").execute()
            total_journalists = journalists_result.count

            # ê¸°ì‚¬ê°€ ìˆëŠ” ê¸°ì ìˆ˜
            active_journalists_result = (
                self.client.client.table("journalists").select("id", count="exact").gt("article_count", 0).execute()
            )
            active_journalists = active_journalists_result.count

            # í‰ê·  ì ìˆ˜ê°€ ìˆëŠ” ê¸°ì ìˆ˜ (AI ë¶„ì„ ì™„ë£Œëœ ê¸°ì‚¬ê°€ ìˆëŠ” ê¸°ì)
            scored_journalists_result = (
                self.client.client.table("journalists")
                .select("id", count="exact")
                .gt("avg_clickbait_score", 0)
                .execute()
            )
            scored_journalists = scored_journalists_result.count

            # ì „ì²´ ê¸°ì‚¬ ìˆ˜
            articles_result = self.client.client.table("articles").select("id", count="exact").execute()
            total_articles = articles_result.count

            # AI ë¶„ì„ ì™„ë£Œëœ ê¸°ì‚¬ ìˆ˜
            scored_articles_result = (
                self.client.client.table("articles")
                .select("id", count="exact")
                .not_.is_("clickbait_score", "null")
                .execute()
            )
            scored_articles = scored_articles_result.count

            return {
                "total_journalists": total_journalists,
                "active_journalists": active_journalists,
                "scored_journalists": scored_journalists,
                "total_articles": total_articles,
                "scored_articles": scored_articles,
                "pending_articles": total_articles - scored_articles,
            }

        except Exception as e:
            logger.error(f"í†µê³„ ìš”ì•½ ì¡°íšŒ ì˜¤ë¥˜: {e}")
            return {}

    def fix_inconsistent_stats(self) -> Dict[str, Any]:
        """
        í†µê³„ ë¶ˆì¼ì¹˜ ê°ì§€ ë° ìˆ˜ì • (Supabase í˜¸í™˜ ë°©ì‹)

        Returns:
            ìˆ˜ì • ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        """
        try:
            logger.info("í†µê³„ ë¶ˆì¼ì¹˜ ê°ì§€ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...")

            # ëª¨ë“  ê¸°ì ì •ë³´ ì¡°íšŒ
            journalists_result = self.client.client.table("journalists").select("*").execute()
            if not journalists_result.data:
                logger.info("ê¸°ìê°€ ì—†ìŠµë‹ˆë‹¤")
                return {"fixed": 0, "total_checked": 0}

            inconsistent_journalists = []
            total_checked = 0

            for journalist in journalists_result.data:
                total_checked += 1
                journalist_id = journalist["id"]
                stored_count = journalist.get("article_count", 0)
                stored_avg = journalist.get("avg_clickbait_score", 0.0)
                stored_max = journalist.get("max_score", 0)

                # í•´ë‹¹ ê¸°ìì˜ ì‹¤ì œ ê¸°ì‚¬ í†µê³„ ê³„ì‚°
                articles_result = (
                    self.client.client.table("articles")
                    .select("clickbait_score")
                    .eq("journalist_id", journalist_id)
                    .execute()
                )

                # ì‹¤ì œ ê°’ ê³„ì‚°
                actual_count = len(articles_result.data)
                scored_articles = [
                    article for article in articles_result.data if article["clickbait_score"] is not None
                ]

                if scored_articles:
                    scores = [article["clickbait_score"] for article in scored_articles]
                    actual_avg = sum(scores) / len(scores)
                    actual_max = max(scores)
                else:
                    actual_avg = 0.0
                    actual_max = 0

                # ë¶ˆì¼ì¹˜ ê°ì§€ (ì†Œìˆ˜ì  2ìë¦¬ê¹Œì§€ ë¹„êµ)
                count_mismatch = stored_count != actual_count
                avg_mismatch = abs(stored_avg - actual_avg) > 0.01
                max_mismatch = stored_max != actual_max

                if count_mismatch or avg_mismatch or max_mismatch:
                    inconsistent_journalists.append(
                        {
                            "id": journalist_id,
                            "name": journalist["name"],
                            "publisher": journalist["publisher"],
                            "stored_count": stored_count,
                            "stored_avg": stored_avg,
                            "stored_max": stored_max,
                            "actual_count": actual_count,
                            "actual_avg": actual_avg,
                            "actual_max": actual_max,
                        }
                    )

                    logger.warning(
                        f"í†µê³„ ë¶ˆì¼ì¹˜ ë°œê²¬: {journalist['name']} ({journalist['publisher']}) "
                        f"- ì €ì¥ëœ ê°’: {stored_count}/{stored_avg:.2f}/{stored_max} "
                        f"- ì‹¤ì œ ê°’: {actual_count}/{actual_avg:.2f}/{actual_max}"
                    )

            if not inconsistent_journalists:
                logger.info("í†µê³„ ë¶ˆì¼ì¹˜ê°€ ë°œê²¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
                return {"fixed": 0, "total_checked": total_checked, "total_inconsistent": 0}

            # ë¶ˆì¼ì¹˜ ìˆ˜ì •
            fixed_count = 0
            for journalist in inconsistent_journalists:
                try:
                    if self.update_journalist_stats_manual(journalist["id"]):
                        fixed_count += 1
                        logger.info(f"ìˆ˜ì • ì™„ë£Œ: {journalist['name']} ({journalist['publisher']})")
                    else:
                        logger.error(f"ìˆ˜ì • ì‹¤íŒ¨: {journalist['name']} ({journalist['publisher']})")
                except Exception as e:
                    logger.error(f"ìˆ˜ì • ì¤‘ ì˜¤ë¥˜ [{journalist['name']}]: {e}")

            result = {
                "fixed": fixed_count,
                "total_inconsistent": len(inconsistent_journalists),
                "total_checked": total_checked,
            }

            logger.info(f"í†µê³„ ë¶ˆì¼ì¹˜ ìˆ˜ì • ì™„ë£Œ: {fixed_count}/{len(inconsistent_journalists)}ê±´")
            return result

        except Exception as e:
            logger.error(f"í†µê³„ ë¶ˆì¼ì¹˜ ìˆ˜ì • ì˜¤ë¥˜: {e}")
            return {"fixed": 0, "total_checked": 0, "error": str(e)}
